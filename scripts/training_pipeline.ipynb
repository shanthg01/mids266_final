{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training Pipeline for LSTMABAR\n",
    "Includes data loading, training loop, and evaluation\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import json\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lstmabar_model import LSTMABAR, LSTMABARTrainer\n",
    "from musiccaps_loader import MusicCapsLoader\n",
    "from improved_text_encoders import ImprovedTextEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicCapsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for MusicCaps with archetype annotations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        training_data_path: str,\n",
    "        sample_rate: int = 44100,\n",
    "        audio_duration: float = 2.0,\n",
    "        augment: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            training_data_path: Path to .npz file with training data\n",
    "            sample_rate: Audio sample rate\n",
    "            audio_duration: Duration to load from each audio file\n",
    "            augment: Whether to apply data augmentation\n",
    "        \"\"\"\n",
    "        self.sample_rate = sample_rate\n",
    "        self.audio_duration = audio_duration\n",
    "        self.augment = augment\n",
    "        self.target_samples = int(sample_rate * audio_duration)\n",
    "        \n",
    "        # Load training data\n",
    "        print(f\"Loading training data from {training_data_path}\")\n",
    "        data = np.load(training_data_path, allow_pickle=True)\n",
    "        \n",
    "        self.archetype_vectors = torch.from_numpy(data['archetype_vectors']).float()\n",
    "        self.descriptions = data['descriptions'].tolist()\n",
    "        self.audio_paths = data['audio_paths'].tolist()\n",
    "        self.archetype_order = data['archetype_order'].tolist()\n",
    "        \n",
    "        print(f\"Loaded {len(self.descriptions)} training examples\")\n",
    "        \n",
    "        # Filter out samples with missing audio files\n",
    "        self.valid_indices = self._find_valid_samples()\n",
    "        print(f\"Found {len(self.valid_indices)} samples with valid audio files\")\n",
    "    \n",
    "    def _find_valid_samples(self) -> List[int]:\n",
    "        \"\"\"Find indices with existing audio files\"\"\"\n",
    "        valid = []\n",
    "        for i, audio_path in enumerate(self.audio_paths):\n",
    "            if Path(audio_path).exists():\n",
    "                valid.append(i)\n",
    "        return valid\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.valid_indices)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict:\n",
    "        \"\"\"\n",
    "        Get a single training sample\n",
    "        \n",
    "        Returns:\n",
    "            Dict with 'audio', 'description', 'archetype_weights'\n",
    "        \"\"\"\n",
    "        # Map to valid index\n",
    "        actual_idx = self.valid_indices[idx]\n",
    "        \n",
    "        # Load audio\n",
    "        audio_path = self.audio_paths[actual_idx]\n",
    "        audio, sr = librosa.load(\n",
    "            audio_path,\n",
    "            sr=self.sample_rate,\n",
    "            duration=self.audio_duration\n",
    "        )\n",
    "        \n",
    "        # Pad or trim to exact length\n",
    "        if len(audio) < self.target_samples:\n",
    "            audio = np.pad(audio, (0, self.target_samples - len(audio)))\n",
    "        else:\n",
    "            audio = audio[:self.target_samples]\n",
    "        \n",
    "        # Apply augmentation if enabled\n",
    "        if self.augment:\n",
    "            audio = self._augment_audio(audio)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        audio_tensor = torch.from_numpy(audio).float()\n",
    "        \n",
    "        # Get description and archetype weights\n",
    "        description = self.descriptions[actual_idx]\n",
    "        archetype_weights = self.archetype_vectors[actual_idx]\n",
    "        \n",
    "        return {\n",
    "            'audio': audio_tensor,\n",
    "            'description': description,\n",
    "            'archetype_weights': archetype_weights\n",
    "        }\n",
    "    \n",
    "    def _augment_audio(self, audio: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply random audio augmentations\"\"\"\n",
    "        # Random gain (±3dB)\n",
    "        if np.random.random() > 0.5:\n",
    "            gain_db = np.random.uniform(-3, 3)\n",
    "            audio = audio * (10 ** (gain_db / 20))\n",
    "        \n",
    "        # Random time shift\n",
    "        if np.random.random() > 0.5:\n",
    "            shift = np.random.randint(-self.sample_rate // 10, self.sample_rate // 10)\n",
    "            audio = np.roll(audio, shift)\n",
    "        \n",
    "        # Add slight noise\n",
    "        if np.random.random() > 0.5:\n",
    "            noise = np.random.randn(len(audio)) * 0.005\n",
    "            audio = audio + noise\n",
    "        \n",
    "        return audio\n",
    "\n",
    "\n",
    "def collate_fn(batch: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    Custom collate function for DataLoader\n",
    "    Handles variable-length descriptions\n",
    "    \"\"\"\n",
    "    audio = torch.stack([item['audio'] for item in batch])\n",
    "    descriptions = [item['description'] for item in batch]\n",
    "    archetype_weights = torch.stack([item['archetype_weights'] for item in batch])\n",
    "    \n",
    "    return {\n",
    "        'audio': audio,\n",
    "        'descriptions': descriptions,\n",
    "        'archetype_weights': archetype_weights\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingPipeline:\n",
    "    \"\"\"\n",
    "    Complete training pipeline for LSTMABAR\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model: LSTMABAR,\n",
    "        train_dataset: MusicCapsDataset,\n",
    "        val_dataset: Optional[MusicCapsDataset] = None,\n",
    "        batch_size: int = 16,\n",
    "        learning_rate: float = 1e-4,\n",
    "        num_epochs: int = 50,\n",
    "        checkpoint_dir: str = 'checkpoints',\n",
    "        log_interval: int = 10\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.checkpoint_dir = Path(checkpoint_dir)\n",
    "        self.log_interval = log_interval\n",
    "        \n",
    "        # Create checkpoint directory\n",
    "        self.checkpoint_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Create data loaders\n",
    "        self.train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=collate_fn,\n",
    "            num_workers=0,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        if val_dataset is not None:\n",
    "            self.val_loader = DataLoader(\n",
    "                val_dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                collate_fn=collate_fn,\n",
    "                num_workers=0,\n",
    "                pin_memory=True\n",
    "            )\n",
    "        else:\n",
    "            self.val_loader = None\n",
    "        \n",
    "        # Initialize trainer\n",
    "        self.trainer = LSTMABARTrainer(\n",
    "            model,\n",
    "            learning_rate=learning_rate,\n",
    "            loss_weights={\n",
    "                'contrastive': 0.7,\n",
    "                'archetype_prediction': 0.2,\n",
    "                'audio_archetype_supervision': 0.1\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(f\"Training pipeline initialized:\")\n",
    "        print(f\"  Training samples: {len(train_dataset)}\")\n",
    "        print(f\"  Validation samples: {len(val_dataset) if val_dataset else 0}\")\n",
    "        print(f\"  Batch size: {batch_size}\")\n",
    "        print(f\"  Total epochs: {num_epochs}\")\n",
    "        print(f\"  Steps per epoch: {len(self.train_loader)}\")\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Run complete training loop\"\"\"\n",
    "        best_val_loss = float('inf')\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Epoch {epoch+1}/{self.num_epochs}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            # Training\n",
    "            train_losses = self.trainer.train_epoch(self.train_loader, epoch)\n",
    "            print(f\"\\nTrain Losses: {train_losses}\")\n",
    "            \n",
    "            # Validation\n",
    "            if self.val_loader is not None:\n",
    "                val_losses = {'total': 0.0}\n",
    "                for batch in self.val_loader:\n",
    "                    batch_losses = self.trainer.validate(\n",
    "                        batch['descriptions'],\n",
    "                        batch['audio'].to(self.model.device),\n",
    "                        batch['archetype_weights'].to(self.model.device)\n",
    "                    )\n",
    "                    for key in batch_losses:\n",
    "                        val_losses[key] = val_losses.get(key, 0.0) + batch_losses[key]\n",
    "                \n",
    "                # Average validation losses\n",
    "                for key in val_losses:\n",
    "                    val_losses[key] /= len(self.val_loader)\n",
    "                \n",
    "                print(f\"Val Losses: {val_losses}\")\n",
    "                \n",
    "                # Save best model\n",
    "                if val_losses['total'] < best_val_loss:\n",
    "                    best_val_loss = val_losses['total']\n",
    "                    save_path = self.checkpoint_dir / 'best_model.pth'\n",
    "                    self.model.save_checkpoint(\n",
    "                        str(save_path),\n",
    "                        epoch,\n",
    "                        self.trainer.optimizer.state_dict()\n",
    "                    )\n",
    "                    print(f\"✓ Best model saved (val_loss: {best_val_loss:.4f})\")\n",
    "            \n",
    "            # Save periodic checkpoint\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                save_path = self.checkpoint_dir / f'checkpoint_epoch_{epoch+1}.pth'\n",
    "                self.model.save_checkpoint(\n",
    "                    str(save_path),\n",
    "                    epoch,\n",
    "                    self.trainer.optimizer.state_dict()\n",
    "                )\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"Training complete!\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Save final model\n",
    "        final_path = self.checkpoint_dir / 'final_model.pth'\n",
    "        self.model.save_checkpoint(\n",
    "            str(final_path),\n",
    "            self.num_epochs - 1,\n",
    "            self.trainer.optimizer.state_dict()\n",
    "        )\n",
    "        \n",
    "        # Plot training history\n",
    "        self.plot_training_history()\n",
    "    \n",
    "    def plot_training_history(self):\n",
    "        \"\"\"Plot training curves\"\"\"\n",
    "        history = self.trainer.history\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Total loss\n",
    "        axes[0].plot(history['train_loss'], label='Train Loss')\n",
    "        if history['val_loss']:\n",
    "            axes[0].plot(history['val_loss'], label='Val Loss')\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('Loss')\n",
    "        axes[0].set_title('Total Loss')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Component losses\n",
    "        axes[1].plot(history['contrastive_loss'], label='Contrastive Loss')\n",
    "        axes[1].plot(history['archetype_loss'], label='Archetype Loss')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('Loss')\n",
    "        axes[1].set_title('Component Losses')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.checkpoint_dir / 'training_history.png', dpi=300)\n",
    "        print(f\"Training history plot saved to {self.checkpoint_dir / 'training_history.png'}\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def prepare_musiccaps_data(\n",
    "    csv_path: str,\n",
    "    audio_dir: str = 'musiccaps_audio',\n",
    "    output_path: str = 'musiccaps_training_data.npz',\n",
    "    max_downloads: int = 5000,\n",
    "    train_split: float = 0.7,\n",
    "    val_split: float = 0.15,\n",
    "    test_split: float = 0.15,\n",
    "    random_seed: int = 42\n",
    ") -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Prepare MusicCaps dataset for training\n",
    "\n",
    "    Args:\n",
    "        csv_path: Path to MusicCaps CSV\n",
    "        audio_dir: Directory to save audio\n",
    "        output_path: Base path for output files\n",
    "        max_downloads: Max clips to download\n",
    "        train_split: Fraction for training (default 0.7)\n",
    "        val_split: Fraction for validation (default 0.15)\n",
    "        test_split: Fraction for testing (default 0.15)\n",
    "        random_seed: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (train_path, val_path, test_path) .npz files\n",
    "    \"\"\"\n",
    "\n",
    "    assert abs(train_split + val_split + test_split - 1.0) < 1e-6, \\\n",
    "        \"Splits must sum to 1.0\"\n",
    "\n",
    "    print(\"=== Preparing MusicCaps Dataset ===\")\n",
    "    \n",
    "    # Load and process MusicCaps\n",
    "    loader = MusicCapsLoader(csv_path, audio_dir)\n",
    "    \n",
    "    # Download audio clips\n",
    "    print(f\"\\nDownloading up to {max_downloads} audio clips...\")\n",
    "    downloaded, failed = loader.download_audio_clips(\n",
    "        max_clips=max_downloads,\n",
    "        use_balanced_subset=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Successfully downloaded: {len(downloaded)}\")\n",
    "    print(f\"Failed: {len(failed)}\")\n",
    "    \n",
    "    # Create archetype training data\n",
    "    print(\"\\nCreating archetype training data...\")\n",
    "    training_data = loader.create_archetype_training_data(use_tfidf_weighting=True)\n",
    "    \n",
    "    # Shuffle data for random splits\n",
    "    np.random.seed(random_seed)\n",
    "    indices = np.random.permutation(len(training_data))\n",
    "    training_data = [training_data[i] for i in indices]\n",
    "    \n",
    "    # Calculate split points\n",
    "    n_total = len(training_data)\n",
    "    n_train = int(n_total * train_split)\n",
    "    n_val = int(n_total * val_split)\n",
    "    n_test = n_total - n_train - n_val\n",
    "    \n",
    "    # Split data\n",
    "    train_data = training_data[:n_train]\n",
    "    val_data = training_data[n_train:n_train + n_val]\n",
    "    test_data = training_data[n_train + n_val:]\n",
    "    \n",
    "    print(f\"\\nDataset split:\")\n",
    "    print(f\"  Train: {len(train_data)} samples ({train_split*100:.1f}%)\")\n",
    "    print(f\"  Val:   {len(val_data)} samples ({val_split*100:.1f}%)\")\n",
    "    print(f\"  Test:  {len(test_data)} samples ({test_split*100:.1f}%)\")\n",
    "    \n",
    "    # Save train set\n",
    "    train_path = output_path.replace('.npz', '_train.npz')\n",
    "    vectors_train = np.array([item['archetype_vector'] for item in train_data])\n",
    "    descriptions_train = [item['description'] for item in train_data]\n",
    "    audio_paths_train = [item['audio_path'] for item in train_data]\n",
    "    \n",
    "    np.savez_compressed(\n",
    "        train_path,\n",
    "        archetype_vectors=vectors_train,\n",
    "        descriptions=descriptions_train,\n",
    "        audio_paths=audio_paths_train,\n",
    "        archetype_order=train_data[0]['archetype_order']\n",
    "    )\n",
    "    print(f\"\\n✓ Saved train set: {train_path}\")\n",
    "    \n",
    "    # Save val set\n",
    "    val_path = output_path.replace('.npz', '_val.npz')\n",
    "    vectors_val = np.array([item['archetype_vector'] for item in val_data])\n",
    "    descriptions_val = [item['description'] for item in val_data]\n",
    "    audio_paths_val = [item['audio_path'] for item in val_data]\n",
    "    \n",
    "    np.savez_compressed(\n",
    "        val_path,\n",
    "        archetype_vectors=vectors_val,\n",
    "        descriptions=descriptions_val,\n",
    "        audio_paths=audio_paths_val,\n",
    "        archetype_order=val_data[0]['archetype_order']\n",
    "    )\n",
    "    print(f\"✓ Saved val set: {val_path}\")\n",
    "    \n",
    "    # Save test set\n",
    "    test_path = output_path.replace('.npz', '_test.npz')\n",
    "    vectors_test = np.array([item['archetype_vector'] for item in test_data])\n",
    "    descriptions_test = [item['description'] for item in test_data]\n",
    "    audio_paths_test = [item['audio_path'] for item in test_data]\n",
    "    \n",
    "    np.savez_compressed(\n",
    "        test_path,\n",
    "        archetype_vectors=vectors_test,\n",
    "        descriptions=descriptions_test,\n",
    "        audio_paths=audio_paths_test,\n",
    "        archetype_order=test_data[0]['archetype_order']\n",
    "    )\n",
    "    print(f\"✓ Saved test set: {test_path}\")\n",
    "    \n",
    "    return train_path, val_path, test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\\n\")\n",
    "\n",
    "# # Old Baseline Configuration\n",
    "# config = {\n",
    "#     'embedding_dim': 768,\n",
    "#     'audio_architecture': 'resnet',  # or 'ast'\n",
    "#     'sample_rate': 44100,\n",
    "#     'audio_duration': 2.0,\n",
    "#     'batch_size': 16,\n",
    "#     'learning_rate': 1e-4,\n",
    "#     'num_epochs': 20,\n",
    "#     'max_downloads': 5000\n",
    "# }\n",
    "\n",
    "# Approach C Improved Config\n",
    "# New Configuration\n",
    "config = {\n",
    "    'embedding_dim': 768,\n",
    "    'audio_architecture': 'resnet',\n",
    "    'audio_duration': 2.0,\n",
    "    'sample_rate': 44100,\n",
    "    'batch_size': 32,  # Increased from 16\n",
    "    'learning_rate': 3e-4,  # Increased from 1e-4\n",
    "    'num_epochs': 30,  # Increased from 20\n",
    "    'weight_decay': 0.01,  # Added regularization\n",
    "    'max_downloads': 5000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/zain/.cache/kagglehub/datasets/googleai/musiccaps/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Download data (run once)\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"googleai/musiccaps\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "csv_path = f\"{path}/musiccaps-public.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Preparing MusicCaps dataset with train/val/test split...\n",
      "=== Preparing MusicCaps Dataset ===\n",
      "Loaded 5521 MusicCaps examples\n",
      "\n",
      "Downloading up to 5000 audio clips...\n",
      "Using balanced subset: 1000 examples\n",
      "✓ Already exists: -bgHkxwoliw\n",
      "✓ Already exists: -kpR93atgd8\n",
      "✓ Already exists: -wymN80CiYU\n",
      "✓ Already exists: 07xGXxIHOL4\n",
      "✓ Already exists: 0PMFAO4TIU4\n",
      "✓ Already exists: 0TV9zvfwFhs\n",
      "✓ Already exists: 0fiOM---7QI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] 0i8VM_EooCs: Video unavailable. This video is no longer available due to a copyright claim by Terrabyte Music Limited\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading 0i8VM_EooCs: ERROR: [youtube] 0i8VM_EooCs: Video unavailable. This video is no longer available due to a copyright claim by Terrabyte Music Limited\n",
      "✗ Failed: 0i8VM_EooCs\n",
      "✓ Already exists: 0jFQ21A6GRA\n",
      "✓ Already exists: 1ACn3u5UnBw\n",
      "✓ Already exists: 1BVSYfNCcv0\n",
      "✓ Already exists: 1JpeDWbgUO8\n",
      "✓ Already exists: 1PKxdTlquCA\n",
      "✓ Already exists: 1Q9DXhXMSFI\n",
      "✓ Already exists: 1TyOPtg0Yfk\n",
      "✓ Already exists: 1V7ReAk9k-4\n",
      "✓ Already exists: 1j4rFfU5XKQ\n",
      "✓ Already exists: 20Vh6z6Ie0E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] 2G5bSYHcJSM: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading 2G5bSYHcJSM: ERROR: [youtube] 2G5bSYHcJSM: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n",
      "✗ Failed: 2G5bSYHcJSM\n",
      "✓ Already exists: 2GWkKVHxGRM\n",
      "✓ Already exists: 2JnlmS1zzls\n",
      "✓ Already exists: 2RU4CSDzS-g\n",
      "✓ Already exists: 2U8Dvh7nwFI\n",
      "✓ Already exists: 2ZfthfWQowE\n",
      "✓ Already exists: 2bCuw7U_Rac\n",
      "✓ Already exists: 2dyEnOo3yJ8\n",
      "✓ Already exists: 2vQTq4QLP8U\n",
      "✓ Already exists: 2xGRCsW6-Bk\n",
      "✓ Already exists: 3JYQgXudiH8\n",
      "✓ Already exists: 3TQmts_MxyQ\n",
      "✓ Already exists: 40D4L5Ndi6k\n",
      "✓ Already exists: 44sbWBFswUY\n",
      "✓ Already exists: 4i11P4OCRfk\n",
      "✓ Already exists: 5JQIsqc8HBc\n",
      "✓ Already exists: 5XXAeSybGK0\n",
      "✓ Already exists: 5ZpVhmhVYoI\n",
      "✓ Already exists: 5_orEetudIA\n",
      "✓ Already exists: 5gyMt0YzPQ0\n",
      "✓ Already exists: 60OIHit4Q-M\n",
      "✓ Already exists: 6N1LWG4aztA\n",
      "✓ Already exists: 6k4lcF9IGUk\n",
      "✓ Already exists: 7-mNJ4IUY5Q\n",
      "✓ Already exists: 7WZwlOrRELI\n",
      "✓ Already exists: 7_q36NyJtQY\n",
      "✓ Already exists: 8BJljuSm2Aw\n",
      "✓ Already exists: 8rCYRgePG-4\n",
      "✓ Already exists: 8zCZzzAaC4I\n",
      "✓ Already exists: 9Qd6AdTq3Ls\n",
      "✓ Already exists: 9UD7qz7DuVY\n",
      "✓ Already exists: 9ZAmdxKLnhs\n",
      "✓ Already exists: 9z4YXc9rjTo\n",
      "✓ Already exists: A4jSRfZ6yd0\n",
      "✓ Already exists: AEyeITzfPa0\n",
      "✓ Already exists: AGNqX_OL-dU\n",
      "✓ Already exists: AHrUfa2H_5s\n",
      "✓ Already exists: ALVS3Q_jNaU\n",
      "✓ Already exists: A_oaLt-n4fQ\n",
      "✓ Already exists: AobHGHJSd-s\n",
      "✓ Already exists: AzWIKyRnhG8\n",
      "✓ Already exists: AzsBSUmhl1M\n",
      "✓ Already exists: B00nfVc4FPI\n",
      "✓ Already exists: B1beLwV4yzw\n",
      "✓ Already exists: B7V_grbxflg\n",
      "✓ Already exists: B8pesuUc8Ek\n",
      "✓ Already exists: BC7dI3lQ2Cg\n",
      "✓ Already exists: BHu95Y_kVQA\n",
      "✓ Already exists: BL181hSAG60\n",
      "✓ Already exists: BMgYWTTJv3s\n",
      "✓ Already exists: BR5MDhvcGM8\n",
      "✓ Already exists: BRTHyoVgZT0\n",
      "✓ Already exists: BS2ZnUhmHj4\n",
      "✓ Already exists: BWKQXn5xDwo\n",
      "                             \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Postprocessing: WARNING: unable to obtain file audio codec with ffprobe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading BXo1Tr_oJds: ERROR: Postprocessing: WARNING: unable to obtain file audio codec with ffprobe\n",
      "✗ Failed: BXo1Tr_oJds\n",
      "✓ Already exists: Bl-lCgr5hGY\n",
      "✓ Already exists: BnkDQXlrIX4\n",
      "✓ Already exists: Byk9p21g51g\n",
      "✓ Already exists: C5MhO2HM2Wg\n",
      "✓ Already exists: C6roSYqchkk\n",
      "✓ Already exists: C8VECv8kicU\n",
      "✓ Already exists: CJjyrDGmxIY\n",
      "✓ Already exists: CP3phqztym0\n",
      "✓ Already exists: CRxIJ7YbcZA\n",
      "✓ Already exists: CWQvCCRuU6k\n",
      "✓ Already exists: CZuH43NPynA\n",
      "✓ Already exists: Cchf2QH63bI\n",
      "✓ Already exists: ChyayWIp_vU\n",
      "✓ Already exists: CphwhKgYHaM\n",
      "✓ Already exists: CzMNiypg1I8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] Czbi1u-gwUU: Video unavailable. This video is no longer available due to a copyright claim by Cheb Hasni\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading Czbi1u-gwUU: ERROR: [youtube] Czbi1u-gwUU: Video unavailable. This video is no longer available due to a copyright claim by Cheb Hasni\n",
      "✗ Failed: Czbi1u-gwUU\n",
      "✓ Already exists: D2w3qHmJrdU\n",
      "✓ Already exists: D3FyfFIKLVc\n",
      "✓ Already exists: D4ccFYk3bhU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] D8-x1T8M4gk: Video unavailable. This video has been removed by the uploader\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading D8-x1T8M4gk: ERROR: [youtube] D8-x1T8M4gk: Video unavailable. This video has been removed by the uploader\n",
      "✗ Failed: D8-x1T8M4gk\n",
      "✓ Already exists: DAPGvg8qOAU\n",
      "✓ Already exists: DCFrCX4HPO8\n",
      "✓ Already exists: DG5d4megH8g\n",
      "✓ Already exists: DGbMEkQerYs\n",
      "✓ Already exists: DKflAAykh6A\n",
      "✓ Already exists: DP2vmsftZHY\n",
      "✓ Already exists: DU5pD63Pv30\n",
      "✓ Already exists: DaiVfxATCEE\n",
      "✓ Already exists: DdxW_JziHTA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] DysXetu2I0E: Video unavailable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading DysXetu2I0E: ERROR: [youtube] DysXetu2I0E: Video unavailable\n",
      "✗ Failed: DysXetu2I0E\n",
      "✓ Already exists: EKZvq0dUk50\n",
      "✓ Already exists: EUNTykrvpok\n",
      "✓ Already exists: EaGhKzpkNso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] EfUUgsioXyU: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading EfUUgsioXyU: ERROR: [youtube] EfUUgsioXyU: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n",
      "✗ Failed: EfUUgsioXyU\n",
      "✓ Already exists: EmSZKb0LdVM\n",
      "✓ Already exists: Es9FNjZ-SHI\n",
      "✓ Already exists: FCzMqo8kh1o\n",
      "✓ Already exists: FDO5BekX478\n",
      "✓ Already exists: FENJIDecy5s\n",
      "✓ Already exists: Fsm-xDmyFKg\n",
      "✓ Already exists: FsnRM2irjvI\n",
      "✓ Already exists: FteW_2gNtD4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] Fv9swdLA-lo: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading Fv9swdLA-lo: ERROR: [youtube] Fv9swdLA-lo: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n",
      "✗ Failed: Fv9swdLA-lo\n",
      "✓ Already exists: G2uCAwYS6w0\n",
      "✓ Already exists: GHQlBD-6rkA\n",
      "✓ Already exists: GJYhDjThTHM\n",
      "✓ Already exists: GLIXnXZEOxY\n",
      "✓ Already exists: GPSqrciDLog\n",
      "✓ Already exists: GQbUpJFArKI\n",
      "✓ Already exists: GYCfrx0ruz4\n",
      "✓ Already exists: GbjtSTTEFK4\n",
      "✓ Already exists: Gc8xf7CJiFY\n",
      "✓ Already exists: GkB_BkyVyPs\n",
      "✓ Already exists: Guu30szkA-0\n",
      "✓ Already exists: H6qzijVEqZQ\n",
      "✓ Already exists: HFH9tcIK_PM\n",
      "✓ Already exists: HFVM5pVTwkM\n",
      "✓ Already exists: HHTgjmgTV6c\n",
      "✓ Already exists: HNf9eHqDT1A\n",
      "✓ Already exists: HS_ikHx4LIQ\n",
      "✓ Already exists: HU7oqkJeItQ\n",
      "✓ Already exists: HYjSrwSm0T4\n",
      "✓ Already exists: HfzEa06vDLg\n",
      "✓ Already exists: Hg4f2xt3oKA\n",
      "✓ Already exists: HkXSX7Kdhms\n",
      "✓ Already exists: Hnk45Z0EAxg\n",
      "✓ Already exists: HzXWXYxXyYA\n",
      "✓ Already exists: ID4AoAfHMVk\n",
      "✓ Already exists: IKq2OF8jq1c\n",
      "✓ Already exists: Ikdb_jA9ehU\n",
      "✓ Already exists: JDBu-3VCyWc\n",
      "✓ Already exists: Jcd63Ev7JXA\n",
      "✓ Already exists: Jdy08IPLKdw\n",
      "✓ Already exists: Jjr0_CbcYdg\n",
      "✓ Already exists: JoBRbtAnbVM\n",
      "✓ Already exists: K-zkbbliQcI\n",
      "✓ Already exists: KB79k456DhI\n",
      "✓ Already exists: KCs_VPmsnKo\n",
      "✓ Already exists: KDzy3ZL626U\n",
      "✓ Already exists: KMQmM12G9Z4\n",
      "✓ Already exists: KdNhYvN4Xoo\n",
      "✓ Already exists: KzvdKLdBw3s\n",
      "✓ Already exists: L0oun9F67tg\n",
      "✓ Already exists: L1s-oPHsOac\n",
      "✓ Already exists: L1s7KZgWXGc\n",
      "✓ Already exists: L5CgdTtGv8o\n",
      "✓ Already exists: LB0u0PrlDHU\n",
      "✓ Already exists: LCzldLY3E4g\n",
      "✓ Already exists: LFYRuK8YstI\n",
      "✓ Already exists: LKUYtvUHn0Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] LRfVQsnaVQE: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading LRfVQsnaVQE: ERROR: [youtube] LRfVQsnaVQE: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n",
      "✗ Failed: LRfVQsnaVQE\n",
      "✓ Already exists: L_nC2BvhRdQ\n",
      "✓ Already exists: LfvdxSBCtFE\n",
      "✓ Already exists: LjihfG0fit0\n",
      "✓ Already exists: LybSS4amIS0\n",
      "✓ Already exists: LzSWdj4izHM\n",
      "✓ Already exists: MHkfPjW0aRg\n",
      "✓ Already exists: MIexFfOsuJs\n",
      "✓ Already exists: MKikHxKeodA\n",
      "✓ Already exists: MM0seezR2F4\n",
      "✓ Already exists: MVYSWTF11Nc\n",
      "✓ Already exists: MY0PsDE3xHs\n",
      "✓ Already exists: MdYXznF3Eac\n",
      "✓ Already exists: MpWGx5odhh8\n",
      "✓ Already exists: MsjeOXuUYG4\n",
      "✓ Already exists: MvnC1TfNiPY\n",
      "✓ Already exists: MzUgHy7SyS8\n",
      "✓ Already exists: N-dzfI3L5ic\n",
      "✓ Already exists: NHA1l_Czm38\n",
      "✓ Already exists: N_Wx35sNqdM\n",
      "✓ Already exists: NlCfScKw_Mk\n",
      "✓ Already exists: NsYVaRI6rXg\n",
      "✓ Already exists: Nt0U-CXK6O0\n",
      "✓ Already exists: NwA9JSlK_lM\n",
      "✓ Already exists: O1RmrE_HfpE\n",
      "✓ Already exists: OB7GyVqufwQ\n",
      "✓ Already exists: OEjgIDubFbg\n",
      "✓ Already exists: OH2SQhJqZDg\n",
      "✓ Already exists: OI7S7vaBT4I\n",
      "✓ Already exists: OKquGBKOgME\n",
      "✓ Already exists: ONfd_rHtL74\n",
      "✓ Already exists: OR_YbeqV5tA\n",
      "✓ Already exists: ORikRIu7s1o\n",
      "✓ Already exists: OcdrbkDm2LQ\n",
      "✓ Already exists: OmjfHQB_lcs\n",
      "✓ Already exists: OpWCljke4oQ\n",
      "✓ Already exists: Orge4_UlvNI\n",
      "✓ Already exists: OrsfEkAhie4\n",
      "✓ Already exists: P-eIhvCaK-s\n",
      "✓ Already exists: P240GHf9Eq4\n",
      "✓ Already exists: P25JeM4lPGw\n",
      "✓ Already exists: P8nK4i8XscM\n",
      "✓ Already exists: PAX2PMha2dU\n",
      "✓ Already exists: PZZxVIIOQPo\n",
      "✓ Already exists: PeWXdkEUPbo\n",
      "✓ Already exists: PvHKu1XRSJ0\n",
      "✓ Already exists: Q789S_9JCio\n",
      "✓ Already exists: QBhhtVMiQBQ\n",
      "✓ Already exists: QK-mjNg8cPo\n",
      "✓ Already exists: QKkhwAAGLIE\n",
      "✓ Already exists: QSaX7QfeWog\n",
      "✓ Already exists: QZoclbefgak\n",
      "✓ Already exists: QfM5-WqvquQ\n",
      "✓ Already exists: QhF0CFyzzAc\n",
      "✓ Already exists: QutCXtWmzIs\n",
      "✓ Already exists: R5JRh08zgMo\n",
      "✓ Already exists: RIiN9Ed1fqU\n",
      "✓ Already exists: ROM--1yVra8\n",
      "✓ Already exists: RPqz3vJYMLQ\n",
      "✓ Already exists: RcfaWoTywcA\n",
      "✓ Already exists: Rdwtr2IX8ek\n",
      "✓ Already exists: RmyyW-TMkVc\n",
      "✓ Already exists: RneRJ5ZnHlE\n",
      "✓ Already exists: RtgHU1UMo5o\n",
      "✓ Already exists: S7TYAcOEPt4\n",
      "✓ Already exists: SG24NL2Xi3A\n",
      "✓ Already exists: SJ9TY-iqD9Q\n",
      "✓ Already exists: S_Z7o4OmU30\n",
      "✓ Already exists: T0oF8MyYhBM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] T6iv9GFIVyU: Video unavailable. This video is no longer available due to a copyright claim by Rishad Zahir\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading T6iv9GFIVyU: ERROR: [youtube] T6iv9GFIVyU: Video unavailable. This video is no longer available due to a copyright claim by Rishad Zahir\n",
      "✗ Failed: T6iv9GFIVyU\n",
      "✓ Already exists: T7A0RejsZIo\n",
      "✓ Already exists: T7ZSZhcsfjA\n",
      "✓ Already exists: TN53jpjqAGI\n",
      "✓ Already exists: TPYNIc_M1ng\n",
      "✓ Already exists: Tp8PG2xae8c\n",
      "✓ Already exists: Tsmx6Pb7CnU\n",
      "✓ Already exists: TworrkXAPuI\n",
      "✓ Already exists: TzPuAqjoL80\n",
      "✓ Already exists: U4UtZeTl2DE\n",
      "✓ Already exists: UDN11Q90Fa4\n",
      "✓ Already exists: UFyOGqmITjM\n",
      "✓ Already exists: UIOnnpaqBy8\n",
      "✓ Already exists: UNJswfXKJ3s\n",
      "✓ Already exists: UQKLBsZJsww\n",
      "✓ Already exists: UcabTrKowlI\n",
      "✓ Already exists: UnFEqUWTefM\n",
      "✓ Already exists: UoxHwOl2gN0\n",
      "✓ Already exists: UrgzGbGVV8I\n",
      "✓ Already exists: UsdoUjuczY4\n",
      "✓ Already exists: UtZofZjccBs\n",
      "✓ Already exists: UvCY9FHpKC8\n",
      "✓ Already exists: V3Vvp5HS90k\n",
      "✓ Already exists: V9jIsOTC1lY\n",
      "✓ Already exists: VCusyLPrFCo\n",
      "✓ Already exists: VG6-MlmCgzI\n",
      "✓ Already exists: VHYxygh1STA\n",
      "✓ Already exists: VL6uF-XeE_A\n",
      "✓ Already exists: VMzn9GytUTk\n",
      "✓ Already exists: VNjYW4OXqTs\n",
      "✓ Already exists: VV-DgnPPhSo\n",
      "✓ Already exists: VV85n-ebuUU\n",
      "✓ Already exists: VZJfkEet6EQ\n",
      "✓ Already exists: Vbcy6KBJsAA\n",
      "✓ Already exists: VfARCp38XtA\n",
      "✓ Already exists: VnJeG9RGUVM\n",
      "✓ Already exists: VswY2mI7Wbo\n",
      "✓ Already exists: Vt3HzkNtOP4\n",
      "✓ Already exists: VuWr1HXHoZg\n",
      "✓ Already exists: VzYc-c-uHjI\n",
      "✓ Already exists: W-nkxlYTdV4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] W0aT3SdtnfY: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading W0aT3SdtnfY: ERROR: [youtube] W0aT3SdtnfY: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n",
      "✗ Failed: W0aT3SdtnfY\n",
      "✓ Already exists: W3lKc2hj4XU\n",
      "✓ Already exists: W7U-glgu4GM\n",
      "✓ Already exists: WCifI6rwOoM\n",
      "✓ Already exists: WEVBqGarEIY\n",
      "✓ Already exists: WMtztIW1f6k\n",
      "✓ Already exists: WPguqXCBQCI\n",
      "✓ Already exists: WTVC7ZI9WtY\n",
      "✓ Already exists: WT_wvvEvkw4\n",
      "✓ Already exists: WaddbqEQ1NE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] We0WIPYrtRE: Video unavailable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading We0WIPYrtRE: ERROR: [youtube] We0WIPYrtRE: Video unavailable\n",
      "✗ Failed: We0WIPYrtRE\n",
      "✓ Already exists: WeDA1mDFSCo\n",
      "✓ Already exists: WgZ8KAnnTb8\n",
      "✓ Already exists: WsDb16qzA5Q\n",
      "✓ Already exists: WtN6uiDikRM\n",
      "✓ Already exists: X96v9LlsjJM\n",
      "✓ Already exists: XE4NRSDLYG8\n",
      "✓ Already exists: XUD-9HkQuTE\n",
      "✓ Already exists: XXBVsNt2Qr8\n",
      "✓ Already exists: XYOnq7ju7o0\n",
      "✓ Already exists: XgOA5oRkL2A\n",
      "✓ Already exists: XjUmXwVlDDo\n",
      "✓ Already exists: XkBXsaSXDJ0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] XvtL_TTLXHY: Video unavailable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading XvtL_TTLXHY: ERROR: [youtube] XvtL_TTLXHY: Video unavailable\n",
      "✗ Failed: XvtL_TTLXHY\n",
      "✓ Already exists: XwhAoMLNYWQ\n",
      "✓ Already exists: XykUpCigu4w\n",
      "✓ Already exists: Y7mTjfgcybQ\n",
      "✓ Already exists: YZx0_GRtvJk\n",
      "✓ Already exists: YcWJUHWt-64\n",
      "✓ Already exists: YrGQKTbiG1g\n",
      "✓ Already exists: YzpzKyzyL0Y\n",
      "✓ Already exists: Z31gI08SMzI\n",
      "✓ Already exists: Z7V7Curou7s\n",
      "✓ Already exists: Z8L3jychP14\n",
      "✓ Already exists: ZEuY5HnECuo\n",
      "✓ Already exists: ZFimyfPWltk\n",
      "✓ Already exists: ZJHlHb-VyDc\n",
      "✓ Already exists: ZLXW4ewrVpQ\n",
      "✓ Already exists: ZMd8mAKe-k8\n",
      "✓ Already exists: ZNGvyFsCx4g\n",
      "✓ Already exists: ZUcHBeueBww\n",
      "✓ Already exists: ZUkh168Nyus\n",
      "✓ Already exists: ZaUaqnLdg6k\n",
      "✓ Already exists: Zhurw43-Y1g\n",
      "✓ Already exists: ZkfKOLp5SxU\n",
      "✓ Already exists: Zlbo8ygfPSM\n",
      "✓ Already exists: ZmgkpmzvL6c\n",
      "✓ Already exists: ZoAfkpmztww\n",
      "✓ Already exists: ZsmfIMEzrQs\n",
      "✓ Already exists: Zt8x7tvP9Qs\n",
      "✓ Already exists: Zz1Bz1a7yPE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] _3OlK_1yQOk: Video unavailable. This video contains content from Storm Labels Inc., who has blocked it on copyright grounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading _3OlK_1yQOk: ERROR: [youtube] _3OlK_1yQOk: Video unavailable. This video contains content from Storm Labels Inc., who has blocked it on copyright grounds\n",
      "✗ Failed: _3OlK_1yQOk\n",
      "✓ Already exists: _43OOP6UEw0\n",
      "✓ Already exists: _78P-0zWJtg\n",
      "✓ Already exists: _9OUh0uwDec\n",
      "✓ Already exists: _R9Ma9rjEWg\n",
      "✓ Already exists: _b5n-mny1lM\n",
      "✓ Already exists: _fKntnlIYTQ\n",
      "✓ Already exists: _gWEpDgPAho\n",
      "✓ Already exists: _h2rFVPCSPE\n",
      "✓ Already exists: _lq8nEXh064\n",
      "✓ Already exists: _m-N4i-ge28\n",
      "✓ Already exists: _mQ6KuA2p6k\n",
      "✓ Already exists: _n3r2inlqBc\n",
      "✓ Already exists: _n9boKzVRhs\n",
      "✓ Already exists: _yXtw_z2xf4\n",
      "✓ Already exists: a2Wuroc8DQU\n",
      "✓ Already exists: aJHv6TV7JpY\n",
      "✓ Already exists: aOGNUGgTQ8k\n",
      "✓ Already exists: aPQTrv2B1sw\n",
      "✓ Already exists: aUH12rRIVDw\n",
      "✓ Already exists: aUXKK9AmrPU\n",
      "✓ Already exists: aUvHaURNgY8\n",
      "✓ Already exists: aW6greyYuO4\n",
      "✓ Already exists: aWK9CcvOK9w\n",
      "✓ Already exists: aY8-pXDdwiw\n",
      "✓ Already exists: ad6UhYwTXXQ\n",
      "✓ Already exists: adYFXYPqo2M\n",
      "✓ Already exists: ajy9PM2SJ6c\n",
      "✓ Already exists: ak7R0_8aKwI\n",
      "✓ Already exists: ao-TFiShaWU\n",
      "✓ Already exists: aryufzYGhbM\n",
      "✓ Already exists: as7MhTe961k\n",
      "✓ Already exists: asT8yaJPP1s\n",
      "✓ Already exists: aupCwPVWsMo\n",
      "✓ Already exists: awax48X8YlU\n",
      "✓ Already exists: ax8hXst_b5g\n",
      "✓ Already exists: b4FomUpNaJE\n",
      "✓ Already exists: b9rgWct9ivI\n",
      "✓ Already exists: bBfi3iEu9fk\n",
      "✓ Already exists: bHiRX6QYwEk\n",
      "✓ Already exists: bJ6e9Ja1ahQ\n",
      "✓ Already exists: bLjOJRg2P_Q\n",
      "✓ Already exists: bOOJRGRy0zc\n",
      "✓ Already exists: bTuKGXDrqdQ\n",
      "✓ Already exists: bVc7-sZAi6s\n",
      "✓ Already exists: bcybO-SMY5E\n",
      "✓ Already exists: bkYWnzw_5Bs\n",
      "✓ Already exists: bl-eQ8XD5CY\n",
      "✓ Already exists: blsYgo-B1k8\n",
      "✓ Already exists: bmVd2Zj8_Cc\n",
      "✓ Already exists: bqMgL5qmZ-k\n",
      "✓ Already exists: bzOeufhFITk\n",
      "✓ Already exists: c9JyKnsegog\n",
      "✓ Already exists: c9h4p6325Xo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] cADT8fUucLQ: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading cADT8fUucLQ: ERROR: [youtube] cADT8fUucLQ: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n",
      "✗ Failed: cADT8fUucLQ\n",
      "✓ Already exists: cBd0yZ27dtA\n",
      "✓ Already exists: cGUhG5PZp0A\n",
      "✓ Already exists: cS2gRhH6it4\n",
      "✓ Already exists: cXEJWtj2kT8\n",
      "✓ Already exists: cYRsnYEPIiM\n",
      "✓ Already exists: cbq6Q2htPRM\n",
      "✓ Already exists: chw8sAKOM5k\n",
      "✓ Already exists: clefr8E-iZQ\n",
      "✓ Already exists: cnvmLwFZr28\n",
      "✓ Already exists: cp8t27oT_ww\n",
      "✓ Already exists: cs-zcTX2tRA\n",
      "✓ Already exists: d1nz5tZckSA\n",
      "✓ Already exists: dBAeAk7dXnU\n",
      "✓ Already exists: dMAp3dvs3kE\n",
      "✓ Already exists: dNOHIxD0j_Q\n",
      "✓ Already exists: dSJpZQ8u_xY\n",
      "✓ Already exists: dSs4xfvATjc\n",
      "✓ Already exists: darQBSIlol8\n",
      "✓ Already exists: deIj55UAxeo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] doX8FjlNPf8: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading doX8FjlNPf8: ERROR: [youtube] doX8FjlNPf8: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n",
      "✗ Failed: doX8FjlNPf8\n",
      "✓ Already exists: dvDSgmqbrM0\n",
      "✓ Already exists: dwAo0dKCyBI\n",
      "✓ Already exists: dwFtlQLdbq0\n",
      "✓ Already exists: dwSj0Rr3vFc\n",
      "✓ Already exists: dy_yFZ6dL34\n",
      "✓ Already exists: e1KHGfMekek\n",
      "✓ Already exists: e2tZmQI8ICw\n",
      "✓ Already exists: e7WPFeDPFB4\n",
      "✓ Already exists: e8wnUU5pIWE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] eHeUipPZHIc: Video unavailable. This video contains content from SVG Music, who has blocked it on copyright grounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading eHeUipPZHIc: ERROR: [youtube] eHeUipPZHIc: Video unavailable. This video contains content from SVG Music, who has blocked it on copyright grounds\n",
      "✗ Failed: eHeUipPZHIc\n",
      "✓ Already exists: eI4PbSh6g_Y\n",
      "✓ Already exists: eM0PkfqGmIE\n",
      "✓ Already exists: eOmQbJljnqE\n",
      "✓ Already exists: eQTK2fo3RoE\n",
      "✓ Already exists: eSesh6vnek8\n",
      "✓ Already exists: eStzDzEopDI\n",
      "✓ Already exists: eW8se7t0s-U\n",
      "✓ Already exists: eWwWwoQLtVg\n",
      "✓ Already exists: eXWBC3XfiXY\n",
      "✓ Already exists: eXrJL1VUQNE\n",
      "✓ Already exists: eYngZ5It0b8\n",
      "✓ Already exists: eZE0RmJESFU\n",
      "✓ Already exists: eZNnuRvrZDU\n",
      "✓ Already exists: e_W17jp40G4\n",
      "✓ Already exists: efTVnvwI2PQ\n",
      "✓ Already exists: eiFyXXqd9Rk\n",
      "✓ Already exists: eiUjc4UPnSs\n",
      "✓ Already exists: esIzFH7vYLY\n",
      "✓ Already exists: euAQCWBX6ns\n",
      "✓ Already exists: evscfdO-oSY\n",
      "✓ Already exists: f3l6KnC8930\n",
      "✓ Already exists: f8nysknTFUo\n",
      "✓ Already exists: fEfe8jznp5Q\n",
      "✓ Already exists: fH9CY48sfJY\n",
      "✓ Already exists: fHNAxa0QaOM\n",
      "✓ Already exists: fPYeqTFc3IQ\n",
      "✓ Already exists: fWypK9RHJJI\n",
      "✓ Already exists: fX8A5Uxc8R0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] fZyq2pM2-dI: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading fZyq2pM2-dI: ERROR: [youtube] fZyq2pM2-dI: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n",
      "✗ Failed: fZyq2pM2-dI\n",
      "✓ Already exists: feC0L9MtghM\n",
      "✓ Already exists: fer_4HvG3aY\n",
      "✓ Already exists: fgCTFyzKQtk\n",
      "✓ Already exists: fhWzjWZqzvs\n",
      "✓ Already exists: fow1TC_MpHs\n",
      "✓ Already exists: fsTVRca31nI\n",
      "✓ Already exists: fsXfBoNcLeM\n",
      "✓ Already exists: ftaHv79hRoY\n",
      "✓ Already exists: fvw3Bi0GONA\n",
      "✓ Already exists: g0scnRzoo9M\n",
      "✓ Already exists: g4xhZgKwiNo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] g8USMvt9np0: We're processing this video. Check back later.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading g8USMvt9np0: ERROR: [youtube] g8USMvt9np0: We're processing this video. Check back later.\n",
      "✗ Failed: g8USMvt9np0\n",
      "✓ Already exists: gAURHUoIK0M\n",
      "✓ Already exists: gBuLpP4klvI\n",
      "✓ Already exists: gDm4IphrlYg\n",
      "✓ Already exists: gDnJoHpSL4M\n",
      "✓ Already exists: gDzi8N3BYMw\n",
      "✓ Already exists: gEvCUcZ6w88\n",
      "✓ Already exists: gFxLnprPgv4\n",
      "✓ Already exists: gRn6OjQf2ZQ\n",
      "✓ Already exists: gWRfk8nCcPs\n",
      "✓ Already exists: gXOyw8a4_Xs\n",
      "✓ Already exists: g_bgmnJ1b_g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] gdtw54I8soM: Video unavailable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading gdtw54I8soM: ERROR: [youtube] gdtw54I8soM: Video unavailable\n",
      "✗ Failed: gdtw54I8soM\n",
      "✓ Already exists: giPa2vVEyVc\n",
      "✓ Already exists: gjJWbtCShqo\n",
      "✓ Already exists: gsBXngKgy-Q\n",
      "✓ Already exists: guRyU4B5LlA\n",
      "✓ Already exists: guYWKdxrtIg\n",
      "✓ Already exists: gxzU5EqNL14\n",
      "✓ Already exists: h0-6U948u7Y\n",
      "✓ Already exists: h8JS_FEF_fY\n",
      "✓ Already exists: hDsA_ky9Hfw\n",
      "✓ Already exists: hDzmNYd_eaA\n",
      "✓ Already exists: hFj0KUzofNg\n",
      "✓ Already exists: hFqZZrj0rnM\n",
      "✓ Already exists: hQ5OBio4Cy0\n",
      "✓ Already exists: hRbukCd6N68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] hTAWbHXCJ2A: Sign in to confirm your age. This video may be inappropriate for some users. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading hTAWbHXCJ2A: ERROR: [youtube] hTAWbHXCJ2A: Sign in to confirm your age. This video may be inappropriate for some users. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n",
      "✗ Failed: hTAWbHXCJ2A\n",
      "✓ Already exists: hTNKYJ6suII\n",
      "✓ Already exists: hUcuXIvDN2E\n",
      "✓ Already exists: hVPQu1UJ2N8\n",
      "✓ Already exists: hgitRq_0410\n",
      "✓ Already exists: hlquKjPgxmY\n",
      "✓ Already exists: hpiFoinUgvY\n",
      "✓ Already exists: hqQvatf1RUY\n",
      "✓ Already exists: hu6sChY-Yps\n",
      "✓ Already exists: i6WtNBpRll0\n",
      "✓ Already exists: i6k1yiyO5jQ\n",
      "✓ Already exists: iBH5X5SKirU\n",
      "✓ Already exists: iBezxlI_f_c\n",
      "✓ Already exists: iCIa_pmLDqs\n",
      "✓ Already exists: iEMTTKA7NxU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] iEQwupwwp0s: The uploader has not made this video available in your country\n",
      "This video is available in United Arab Emirates, Afghanistan, Albania, Armenia, Angola, Antarctica, Argentina, American Samoa, Australia, Aruba, Åland Islands, Azerbaijan, Bosnia and Herzegovina, Bangladesh, Burkina Faso, Bulgaria, Bahrain, Benin, Bermuda, Brunei Darussalam, Bolivia, Plurinational State of, Bonaire, Sint Eustatius and Saba, Brazil, Bhutan, Bouvet Island, Botswana, Belarus, Belize, Cocos (Keeling) Islands, Congo, the Democratic Republic of the, Central African Republic, Congo, Côte d'Ivoire, Cook Islands, Chile, Cameroon, China, Colombia, Costa Rica, Cape Verde, Curaçao, Christmas Island, Cyprus, Czech Republic, Denmark, Ecuador, Estonia, Western Sahara, Spain, Finland, Fiji, Falkland Islands (Malvinas), Micronesia, Federated States of, Faroe Islands, Gabon, Georgia, French Guiana, Guernsey, Ghana, Gibraltar, Greenland, Gambia, Guinea, Guadeloupe, Equatorial Guinea, Greece, South Georgia and the South Sandwich Islands, Guatemala, Guam, Guinea-Bissau, Guyana, Hong Kong, Heard Island and McDonald Islands, Honduras, Croatia, Hungary, Indonesia, Israel, Isle of Man, India, British Indian Ocean Territory, Iraq, Iran, Islamic Republic of, Iceland, Italy, Jersey, Jordan, Japan, Kyrgyzstan, Cambodia, Kiribati, Korea, Democratic People's Republic of, Korea, Republic of, Kuwait, Cayman Islands, Kazakhstan, Lao People's Democratic Republic, Lebanon, Sri Lanka, Liberia, Lesotho, Lithuania, Latvia, Moldova, Republic of, Montenegro, Marshall Islands, Macedonia, the Former Yugoslav Republic of, Mali, Myanmar, Mongolia, Macao, Northern Mariana Islands, Malta, Maldives, Mexico, Malaysia, Namibia, New Caledonia, Niger, Norfolk Island, Nigeria, Nicaragua, Norway, Nepal, Nauru, Niue, New Zealand, Oman, Panama, Peru, French Polynesia, Papua New Guinea, Philippines, Pakistan, Poland, Saint Pierre and Miquelon, Pitcairn, Palestine, State of, Palau, Paraguay, Qatar, Romania, Serbia, Russian Federation, Saudi Arabia, Solomon Islands, Sweden, Singapore, Slovenia, Svalbard and Jan Mayen, Slovakia, Sierra Leone, San Marino, Senegal, Suriname, Sao Tome and Principe, El Salvador, Sint Maarten (Dutch part), Syrian Arab Republic, Swaziland, Chad, French Southern Territories, Togo, Thailand, Tajikistan, Tokelau, Timor-Leste, Turkmenistan, Tonga, Turkey, Tuvalu, Taiwan, Province of China, Ukraine, United States Minor Outlying Islands, Uruguay, Uzbekistan, Holy See (Vatican City State), Venezuela, Bolivarian Republic of, Viet Nam, Vanuatu, Wallis and Futuna, Samoa, Yemen, Mayotte, South Africa.\n",
      "You might want to use a VPN or a proxy server (with --proxy) to workaround.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading iEQwupwwp0s: ERROR: [youtube] iEQwupwwp0s: The uploader has not made this video available in your country\n",
      "This video is available in United Arab Emirates, Afghanistan, Albania, Armenia, Angola, Antarctica, Argentina, American Samoa, Australia, Aruba, Åland Islands, Azerbaijan, Bosnia and Herzegovina, Bangladesh, Burkina Faso, Bulgaria, Bahrain, Benin, Bermuda, Brunei Darussalam, Bolivia, Plurinational State of, Bonaire, Sint Eustatius and Saba, Brazil, Bhutan, Bouvet Island, Botswana, Belarus, Belize, Cocos (Keeling) Islands, Congo, the Democratic Republic of the, Central African Republic, Congo, Côte d'Ivoire, Cook Islands, Chile, Cameroon, China, Colombia, Costa Rica, Cape Verde, Curaçao, Christmas Island, Cyprus, Czech Republic, Denmark, Ecuador, Estonia, Western Sahara, Spain, Finland, Fiji, Falkland Islands (Malvinas), Micronesia, Federated States of, Faroe Islands, Gabon, Georgia, French Guiana, Guernsey, Ghana, Gibraltar, Greenland, Gambia, Guinea, Guadeloupe, Equatorial Guinea, Greece, South Georgia and the South Sandwich Islands, Guatemala, Guam, Guinea-Bissau, Guyana, Hong Kong, Heard Island and McDonald Islands, Honduras, Croatia, Hungary, Indonesia, Israel, Isle of Man, India, British Indian Ocean Territory, Iraq, Iran, Islamic Republic of, Iceland, Italy, Jersey, Jordan, Japan, Kyrgyzstan, Cambodia, Kiribati, Korea, Democratic People's Republic of, Korea, Republic of, Kuwait, Cayman Islands, Kazakhstan, Lao People's Democratic Republic, Lebanon, Sri Lanka, Liberia, Lesotho, Lithuania, Latvia, Moldova, Republic of, Montenegro, Marshall Islands, Macedonia, the Former Yugoslav Republic of, Mali, Myanmar, Mongolia, Macao, Northern Mariana Islands, Malta, Maldives, Mexico, Malaysia, Namibia, New Caledonia, Niger, Norfolk Island, Nigeria, Nicaragua, Norway, Nepal, Nauru, Niue, New Zealand, Oman, Panama, Peru, French Polynesia, Papua New Guinea, Philippines, Pakistan, Poland, Saint Pierre and Miquelon, Pitcairn, Palestine, State of, Palau, Paraguay, Qatar, Romania, Serbia, Russian Federation, Saudi Arabia, Solomon Islands, Sweden, Singapore, Slovenia, Svalbard and Jan Mayen, Slovakia, Sierra Leone, San Marino, Senegal, Suriname, Sao Tome and Principe, El Salvador, Sint Maarten (Dutch part), Syrian Arab Republic, Swaziland, Chad, French Southern Territories, Togo, Thailand, Tajikistan, Tokelau, Timor-Leste, Turkmenistan, Tonga, Turkey, Tuvalu, Taiwan, Province of China, Ukraine, United States Minor Outlying Islands, Uruguay, Uzbekistan, Holy See (Vatican City State), Venezuela, Bolivarian Republic of, Viet Nam, Vanuatu, Wallis and Futuna, Samoa, Yemen, Mayotte, South Africa.\n",
      "You might want to use a VPN or a proxy server (with --proxy) to workaround.\n",
      "✗ Failed: iEQwupwwp0s\n",
      "✓ Already exists: iFSaNmZyPQo\n",
      "✓ Already exists: iMmYVLSb1IY\n",
      "✓ Already exists: iQ7qeIrssds\n",
      "✓ Already exists: iQfPmJ19ZUc\n",
      "✓ Already exists: iS8YQGp2_ng\n",
      "✓ Already exists: iUHqyjf3NcQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] iXgEQj1Fs7g: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading iXgEQj1Fs7g: ERROR: [youtube] iXgEQj1Fs7g: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n",
      "✗ Failed: iXgEQj1Fs7g\n",
      "✓ Already exists: iZjIuV_cTe8\n",
      "✓ Already exists: i_NNY_mgxIs\n",
      "✓ Already exists: i_d4JFg-zT0\n",
      "✓ Already exists: iaDrtIon6FU\n",
      "✓ Already exists: idUZsNLnyDg\n",
      "✓ Already exists: iqEQBCrOLWc\n",
      "✓ Already exists: iqOPJWWKo90\n",
      "✓ Already exists: j43Dwqzd8w8\n",
      "✓ Already exists: jP4M9V_Ka8k\n",
      "✓ Already exists: jPROsr_K710\n",
      "✓ Already exists: jUJNETNCxh0\n",
      "✓ Already exists: jZkHpNnXLB0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] jd1IS7N3u0I: Video unavailable. This video contains content from SME, who has blocked it in your country on copyright grounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading jd1IS7N3u0I: ERROR: [youtube] jd1IS7N3u0I: Video unavailable. This video contains content from SME, who has blocked it in your country on copyright grounds\n",
      "✗ Failed: jd1IS7N3u0I\n",
      "✓ Already exists: jd94Ox7KJ9Q\n",
      "✓ Already exists: je96vkMY60c\n",
      "✓ Already exists: jhgX0OOoytQ\n",
      "✓ Already exists: jjg0TCq3wbY\n",
      "✓ Already exists: joLyjgORwDo\n",
      "✓ Already exists: jqiD3VeM_hY\n",
      "✓ Already exists: jtRse-cDB18\n",
      "✓ Already exists: jx27p7k2lSw\n",
      "✓ Already exists: k-89m72W0j8\n",
      "✓ Already exists: k3A5xX8yfig\n",
      "✓ Already exists: k5kPBsMFlOc\n",
      "✓ Already exists: kAE7Ceg4VgQ\n",
      "✓ Already exists: kCsmvK06SCA\n",
      "✓ Already exists: kQw2NQ_eqyg\n",
      "✓ Already exists: kT0KMsfD4d8\n",
      "✓ Already exists: kUQ1xfK82Q0\n",
      "✓ Already exists: kVYXcbvw9u4\n",
      "✓ Already exists: kVuG_F3qCuY\n",
      "✓ Already exists: kZBFQAQI7Pg\n",
      "✓ Already exists: kbAMGp-TKJo\n",
      "✓ Already exists: kbCh5HrmgN0\n",
      "✓ Already exists: kbquMoJrhC0\n",
      "✓ Already exists: keHCWa6XfGY\n",
      "✓ Already exists: kf-U7I0-DdA\n",
      "✓ Already exists: kg8FwhL_fqs\n",
      "✓ Already exists: kgf4GdKlSWs\n",
      "✓ Already exists: khQN5ylb3H0\n",
      "✓ Already exists: kjn6I3AurgE\n",
      "✓ Already exists: kka6zUtE3h8\n",
      "✓ Already exists: kpsYSXR1wao\n",
      "✓ Already exists: ksImihlU3qM\n",
      "✓ Already exists: ktTrTDQidsE\n",
      "✓ Already exists: ktw_J6ZW0MM\n",
      "✓ Already exists: l5QPXVIxxwk\n",
      "✓ Already exists: l9vYSBR9nio\n",
      "✓ Already exists: lBtAULJAFp0\n",
      "✓ Already exists: lDCDayKyOQA\n",
      "✓ Already exists: lHlOSsnP48c\n",
      "✓ Already exists: lI8aGjIb8Jg\n",
      "✓ Already exists: lIEnbqr3O34\n",
      "✓ Already exists: lNg2y6SRZPo\n",
      "✓ Already exists: lPFsijo8xYs\n",
      "✓ Already exists: lR8am4rK7qQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] lTLsL94ABRs: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading lTLsL94ABRs: ERROR: [youtube] lTLsL94ABRs: Video unavailable. This video is no longer available because the YouTube account associated with this video has been terminated.\n",
      "✗ Failed: lTLsL94ABRs\n",
      "✓ Already exists: lV0-LMVpZLg\n",
      "✓ Already exists: lbB2VQYIMo0\n",
      "✓ Already exists: liuCTk2nPG8\n",
      "✓ Already exists: lqCx0HgF1ZM\n",
      "✓ Already exists: lqeAf-DqE3I\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] lrk00BNiuD4: Video unavailable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading lrk00BNiuD4: ERROR: [youtube] lrk00BNiuD4: Video unavailable\n",
      "✗ Failed: lrk00BNiuD4\n",
      "✓ Already exists: ltZCJ7aPtO0\n",
      "✓ Already exists: ltysCJWnvsI\n",
      "✓ Already exists: lvktro0asjs\n",
      "✓ Already exists: lwdDm3UO5WM\n",
      "✓ Already exists: m3uiITzeM70\n",
      "✓ Already exists: m4Dj_vTsAt0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] m9MQdg0k1t0: Video unavailable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading m9MQdg0k1t0: ERROR: [youtube] m9MQdg0k1t0: Video unavailable\n",
      "✗ Failed: m9MQdg0k1t0\n",
      "✓ Already exists: mBNdDQamtXA\n",
      "✓ Already exists: mBRr_TqLDf4\n",
      "✓ Already exists: mJuJfKbcJcw\n",
      "✓ Already exists: mLaon9oK1OA\n",
      "✓ Already exists: mLm8upEhc_s\n",
      "✓ Already exists: mMf4vJFT8Fw\n",
      "✓ Already exists: mOn13E68Td0\n",
      "✓ Already exists: mPaRs96jtFY\n",
      "✓ Already exists: mQM3Fd3eN9E\n",
      "✓ Already exists: mW0B1sipLBI\n",
      "✓ Already exists: mW5_chAgg8c\n",
      "✓ Already exists: mfZMcNmLxWM\n",
      "✓ Already exists: mhqHHQ1gSvM\n",
      "✓ Already exists: mnSP_ONVS7k\n",
      "✓ Already exists: mqyeBqaUeN8\n",
      "✓ Already exists: muwIU0BHXE0\n",
      "✓ Already exists: mvZLlJpyDyc\n",
      "✓ Already exists: mzDq-abtAKs\n",
      "✓ Already exists: n1fY-23ffl0\n",
      "✓ Already exists: n4PBoAedWVA\n",
      "✓ Already exists: n615BjoN7fI\n",
      "✓ Already exists: nAKUDXMeWeQ\n",
      "✓ Already exists: nBSMh7pgn2o\n",
      "✓ Already exists: nEOPm7TeydY\n",
      "✓ Already exists: nH_lVl3a3Uw\n",
      "✓ Already exists: nIL_xrqjo1g\n",
      "✓ Already exists: nP05Sf4Fgac\n",
      "✓ Already exists: nPlDt1R8Qfc\n",
      "✓ Already exists: nSBDyxxscks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] nSinUcyFFqg: Video unavailable. This video contains content from SME, who has blocked it in your country on copyright grounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading nSinUcyFFqg: ERROR: [youtube] nSinUcyFFqg: Video unavailable. This video contains content from SME, who has blocked it in your country on copyright grounds\n",
      "✗ Failed: nSinUcyFFqg\n",
      "✓ Already exists: nU7x170OvJ4\n",
      "✓ Already exists: nUs5SJyQPnM\n",
      "✓ Already exists: nVsAyArtEh0\n",
      "✓ Already exists: nZ19mW-TMRk\n",
      "✓ Already exists: nZ5_UUUS8X8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] nZmhIHZINL8: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading nZmhIHZINL8: ERROR: [youtube] nZmhIHZINL8: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n",
      "✗ Failed: nZmhIHZINL8\n",
      "✓ Already exists: navn7jCBp_o\n",
      "✓ Already exists: nbYdiazwUQo\n",
      "✓ Already exists: nb_7c2xPKYA\n",
      "✓ Already exists: nc6h6rC3wdk\n",
      "✓ Already exists: ndjLkbP6Y9Y\n",
      "✓ Already exists: nf3LGAL1LZc\n",
      "✓ Already exists: nj6N7m8SeK4\n",
      "✓ Already exists: nnS7TXfTHOE\n",
      "✓ Already exists: nqd7mXvHupU\n",
      "✓ Already exists: nrcfdP6LrLo\n",
      "✓ Already exists: nt2rvdC75uY\n",
      "✓ Already exists: ntfyeC178Tg\n",
      "✓ Already exists: nvuxMnSHHtg\n",
      "✓ Already exists: nvvXOfLs-ng\n",
      "✓ Already exists: nzpnWuk3RjU\n",
      "✓ Already exists: o-ISARPUGlo\n",
      "✓ Already exists: o6ZQNr0Tpz4\n",
      "✓ Already exists: o8FsD7l5er4\n",
      "✓ Already exists: oD0Xp--xxjE\n",
      "✓ Already exists: oFCzd9bJo9A\n",
      "✓ Already exists: oGbNzR_lpSk\n",
      "✓ Already exists: oJyyNWuyig4\n",
      "✓ Already exists: oOiwmRV1PBk\n",
      "✓ Already exists: oOlMzQpK690\n",
      "✓ Already exists: oRVivXC83hA\n",
      "✓ Already exists: oSg1VJHiPOE\n",
      "✓ Already exists: oSoP9Is0UH4\n",
      "✓ Already exists: oTXKGrB3bCA\n",
      "✓ Already exists: oXBGZoBYaLY\n",
      "✓ Already exists: oYEzy8gH6q8\n",
      "✓ Already exists: oZScu7DU5qk\n",
      "✓ Already exists: oZoJ26C6LrU\n",
      "✓ Already exists: oag3I4VRXyM\n",
      "✓ Already exists: oczJZV87k9A\n",
      "✓ Already exists: oh5XmtSAOuM\n",
      "✓ Already exists: ohBNHUUGD3Q\n",
      "✓ Already exists: oqMlq2zWr0c\n",
      "✓ Already exists: oswsd_r-GI8\n",
      "✓ Already exists: ovVrS-q3Rzk\n",
      "✓ Already exists: ow7xqVk8Wjs\n",
      "✓ Already exists: p28jmA01BHo\n",
      "✓ Already exists: p2jnUySmuvA\n",
      "✓ Already exists: pG6yeC3yUY4\n",
      "✓ Already exists: pHzjKCj9INw\n",
      "✓ Already exists: pKDnn0CBIe0\n",
      "✓ Already exists: pKFXFu8st9I\n",
      "✓ Already exists: pNlrM-GhFZU\n",
      "✓ Already exists: pR87Ts3a0e8\n",
      "✓ Already exists: pSzTPGlNa5U\n",
      "✓ Already exists: pWZqzEpygE0\n",
      "✓ Already exists: pWms_9wpRB4\n",
      "✓ Already exists: pYXx0xXZiXk\n",
      "✓ Already exists: pZgzjL5wbtA\n",
      "✓ Already exists: p_dE26TA8ig\n",
      "✓ Already exists: pejDm3j4Y-I\n",
      "✓ Already exists: pmdoDcNBt0E\n",
      "✓ Already exists: pp6eSGANq0Y\n",
      "✓ Already exists: pqsU95TNNP8\n",
      "✓ Already exists: pxEmmUYLHrE\n",
      "✓ Already exists: pyumNmhV4_s\n",
      "✓ Already exists: pzm90xLX9HM\n",
      "✓ Already exists: q7s7C4oNlFo\n",
      "✓ Already exists: q9DzO_I4dXg\n",
      "✓ Already exists: q9zAlMM-A9I\n",
      "✓ Already exists: qAgZ__fk9LY\n",
      "✓ Already exists: qAr3mFkEvco\n",
      "✓ Already exists: qDiTICmdUQg\n",
      "✓ Already exists: qEGNzCWQdqo\n",
      "✓ Already exists: qEJ_jxZzt7k\n",
      "✓ Already exists: qET3h3w35EA\n",
      "✓ Already exists: qKOsbyT8GCU\n",
      "✓ Already exists: qLWWDHLJBBQ\n",
      "✓ Already exists: qOTk01gmrRo\n",
      "✓ Already exists: qRCjs90-1RQ\n",
      "✓ Already exists: qVT6GX1KHUY\n",
      "✓ Already exists: qVdBBOpSoN4\n",
      "✓ Already exists: qVuxCN3JpiM\n",
      "✓ Already exists: qW4kBJsudLI\n",
      "✓ Already exists: qXgSlhWbWLU\n",
      "✓ Already exists: qZ_-5JplSVg\n",
      "✓ Already exists: qZkM3QaeaUM\n",
      "✓ Already exists: qaQjG9SwORU\n",
      "✓ Already exists: qbIPQGY8RRA\n",
      "✓ Already exists: qbexOeoH5hg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] qc1DaM4kdO0: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading qc1DaM4kdO0: ERROR: [youtube] qc1DaM4kdO0: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n",
      "✗ Failed: qc1DaM4kdO0\n",
      "✓ Already exists: qie2k2gZ7wA\n",
      "✓ Already exists: ql7aH8wF6JM\n",
      "✓ Already exists: qlWEAm4AUTU\n",
      "✓ Already exists: qlk02ytcnPU\n",
      "✓ Already exists: qni67aUJbw4\n",
      "✓ Already exists: qpt3umHYfmY\n",
      "✓ Already exists: qrP_H87vFpo\n",
      "✓ Already exists: qrY7PW5guxk\n",
      "✓ Already exists: qsFfUzErXqw\n",
      "✓ Already exists: qsRPTMXFGsA\n",
      "✓ Already exists: qwGT6wvYdLo\n",
      "✓ Already exists: qwI32Si0ipE\n",
      "✓ Already exists: qwOLhVbuhpM\n",
      "✓ Already exists: qxOPhByaK_M\n",
      "✓ Already exists: r0Xvr8maR34\n",
      "✓ Already exists: r43WrKA6ppI\n",
      "✓ Already exists: r6QD2E-YesI\n",
      "✓ Already exists: rC4PNZ1XOmU\n",
      "✓ Already exists: rE7S4nLrThs\n",
      "✓ Already exists: rGEJVUcFA2U\n",
      "✓ Already exists: rJZgUpzqAyY\n",
      "✓ Already exists: rLQ93N6RJC0\n",
      "✓ Already exists: rLtXML8Y5wo\n",
      "✓ Already exists: rNJ0C44bOac\n",
      "✓ Already exists: rPAB0ymJGco\n",
      "✓ Already exists: rTBQmP6Vt0g\n",
      "✓ Already exists: rUIGOcQMaSE\n",
      "✓ Already exists: rVDojJcQdE0\n",
      "✓ Already exists: rWitVrXe5tg\n",
      "✓ Already exists: r_TgaHCsYB0\n",
      "✓ Already exists: rez5KDmIZoc\n",
      "✓ Already exists: rfQ94EXIpTc\n",
      "✓ Already exists: rfa-iUp5UQc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] rfah0bhmYkc: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading rfah0bhmYkc: ERROR: [youtube] rfah0bhmYkc: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n",
      "✗ Failed: rfah0bhmYkc\n",
      "✓ Already exists: rgWm0-a0kAo\n",
      "✓ Already exists: rh0vBy1JD8A\n",
      "✓ Already exists: rkQPSAHNoeI\n",
      "✓ Already exists: rkapTdi8NTQ\n",
      "✓ Already exists: rmKh9uaikTU\n",
      "✓ Already exists: rrWQd5SZK74\n",
      "✓ Already exists: rs5ecH8Lh3s\n",
      "✓ Already exists: rsCQ1PIGcm0\n",
      "✓ Already exists: rsvHQCTgHvg\n",
      "✓ Already exists: s1JHUf3Q_F0\n",
      "✓ Already exists: s1l4Zjqoqdg\n",
      "✓ Already exists: s2GctT6NuyQ\n",
      "✓ Already exists: s2O2xaRfje0\n",
      "✓ Already exists: s2iIZ2WNuKY\n",
      "✓ Already exists: s4PN7iTLdVM\n",
      "✓ Already exists: s6U8DtBK3Us\n",
      "✓ Already exists: sC7T0sEG6ek\n",
      "✓ Already exists: sEGxoHiAPiQ\n",
      "✓ Already exists: sH_nDqYVq5E\n",
      "✓ Already exists: sHbGsZUsisE\n",
      "✓ Already exists: sIA-IuTI7AY\n",
      "✓ Already exists: sK6ltq0-zgY\n",
      "✓ Already exists: sOSU7p9pLjs\n",
      "✓ Already exists: sOyHkcK_lOA\n",
      "✓ Already exists: sR8rlTIU8_Y\n",
      "✓ Already exists: sTcaIARuemA\n",
      "✓ Already exists: sVF7NNvdoJc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] sXwa1Akj1t0: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading sXwa1Akj1t0: ERROR: [youtube] sXwa1Akj1t0: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n",
      "✗ Failed: sXwa1Akj1t0\n",
      "✓ Already exists: sYIymaJi6tc\n",
      "✓ Already exists: sZuhztdaFYA\n",
      "✓ Already exists: sZwZ2fOWWSg\n",
      "✓ Already exists: s_BKo_1LzJM\n",
      "✓ Already exists: sfmAeijj5cM\n",
      "✓ Already exists: sgJT5lIFttM\n",
      "✓ Already exists: sgwvhvkNELc\n",
      "✓ Already exists: si_IAMPOXlQ\n",
      "✓ Already exists: sm7eBFHtdeA\n",
      "✓ Already exists: swIXVQtP_TI\n",
      "✓ Already exists: t-CMJ6RsZzY\n",
      "✓ Already exists: t-CjLfu9zCk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] t-yy7v7P0IE: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading t-yy7v7P0IE: ERROR: [youtube] t-yy7v7P0IE: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n",
      "✗ Failed: t-yy7v7P0IE\n",
      "✓ Already exists: t12O05LVSBA\n",
      "✓ Already exists: t6jlx6jAb-Q\n",
      "✓ Already exists: t7oAteGa55g\n",
      "✓ Already exists: tEdeb9eSKDI\n",
      "✓ Already exists: tG5C-Smp-eY\n",
      "✓ Already exists: tGUWSgewh0A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] tGic59TlrVg: Video unavailable. This video is not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading tGic59TlrVg: ERROR: [youtube] tGic59TlrVg: Video unavailable. This video is not available\n",
      "✗ Failed: tGic59TlrVg\n",
      "✓ Already exists: tGv_L09pf6E\n",
      "✓ Already exists: tIRHm8VhK_4\n",
      "✓ Already exists: tKawN2sxhYc\n",
      "✓ Already exists: tPJMr890HeE\n",
      "✓ Already exists: tQ1Nl4Dy2aI\n",
      "✓ Already exists: tRA-5inwlMI\n",
      "✓ Already exists: tV3rvUSlVnY\n",
      "✓ Already exists: tWByqbOvYQE\n",
      "✓ Already exists: tWexzTJPxQs\n",
      "✓ Already exists: tWseBEYhE1M\n",
      "✓ Already exists: tZgww16UyU8\n",
      "✓ Already exists: tcOHcop3sCQ\n",
      "✓ Already exists: tdrz4EkIsow\n",
      "✓ Already exists: teyDfFbVMSY\n",
      "✓ Already exists: tk4s-nlhmEQ\n",
      "✓ Already exists: tmabzx6yxqs\n",
      "✓ Already exists: tmpVzeD_M5s\n",
      "✓ Already exists: tt5-i1R78ms\n",
      "✓ Already exists: tvcJENqxr1c\n",
      "✓ Already exists: tw0BGErgupk\n",
      "✓ Already exists: tz2TlSMmTp4\n",
      "✓ Already exists: u6tgeRXOxnU\n",
      "✓ Already exists: u9n4R78UBtA\n",
      "✓ Already exists: uARzr9CAemI\n",
      "✓ Already exists: uAYPacrJnyQ\n",
      "✓ Already exists: uAgizG1hYw0\n",
      "✓ Already exists: uBENjCPS8LI\n",
      "✓ Already exists: uDqVzJtaxOc\n",
      "✓ Already exists: uF1KTW5rT-s\n",
      "✓ Already exists: uGQ7QnKqeY4\n",
      "✓ Already exists: uHgpDP_4Lsc\n",
      "✓ Already exists: uJPW9BEhU6Y\n",
      "✓ Already exists: uKGo4phKqLM\n",
      "✓ Already exists: uNUx8rqcy0M\n",
      "✓ Already exists: uPGasFKZSBo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] uQTCfT5XDzQ: Video unavailable. This video contains content from UMPG Publishing, who has blocked it in your country on copyright grounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading uQTCfT5XDzQ: ERROR: [youtube] uQTCfT5XDzQ: Video unavailable. This video contains content from UMPG Publishing, who has blocked it in your country on copyright grounds\n",
      "✗ Failed: uQTCfT5XDzQ\n",
      "✓ Already exists: uT-S_JC_GzU\n",
      "✓ Already exists: uTfLf1Y8hhM\n",
      "✓ Already exists: uUNlJ4KZTPE\n",
      "✓ Already exists: uXMMzpgrY2g\n",
      "✓ Already exists: uYCMVgUAwnM\n",
      "✓ Already exists: uYYpqx0rzok\n",
      "✓ Already exists: uZesGREO0eI\n",
      "✓ Already exists: u_TfWvyYY0Y\n",
      "✓ Already exists: uiHyWdYkBvY\n",
      "✓ Already exists: uoee1ikakWY\n",
      "✓ Already exists: ura8EjHjGC4\n",
      "✓ Already exists: usrzF-0GbLY\n",
      "✓ Already exists: uuHTPvG-BYI\n",
      "✓ Already exists: uwPeQy7ZtGo\n",
      "✓ Already exists: uy3nQ9VYE-Q\n",
      "✓ Already exists: v0tYHz5mk4I\n",
      "✓ Already exists: v29jCrlSCmE\n",
      "✓ Already exists: v2Ng8iGwf40\n",
      "✓ Already exists: v582kPp43Mg\n",
      "✓ Already exists: v5nB2OJnCko\n",
      "✓ Already exists: v6A7Iggebm4\n",
      "✓ Already exists: v88cAXP03As\n",
      "✓ Already exists: vBkDLBO-Aok\n",
      "✓ Already exists: vDrbslhtX8o\n",
      "✓ Already exists: vEMNk-lbGTE\n",
      "✓ Already exists: vEt13GxzDKk\n",
      "✓ Already exists: vK9x7UQ9Y7k\n",
      "✓ Already exists: vKjC5HTH22o\n",
      "✓ Already exists: vMU7ZKY2Eso\n",
      "✓ Already exists: vNPx6RS8PiM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] vOAXAoHtl7o: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading vOAXAoHtl7o: ERROR: [youtube] vOAXAoHtl7o: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n",
      "✗ Failed: vOAXAoHtl7o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] vQHKa69Mkzo: Video unavailable. This video contains content from TV Tokyo Anime Rights Management, who has blocked it in your country on copyright grounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading vQHKa69Mkzo: ERROR: [youtube] vQHKa69Mkzo: Video unavailable. This video contains content from TV Tokyo Anime Rights Management, who has blocked it in your country on copyright grounds\n",
      "✗ Failed: vQHKa69Mkzo\n",
      "✓ Already exists: vWiq7n4yTAw\n",
      "✓ Already exists: vYP60jdTupc\n",
      "✓ Already exists: vgpV6F9tge8\n",
      "✓ Already exists: vmBkZflwViA\n",
      "✓ Already exists: vmz9kAEiTSc\n",
      "✓ Already exists: vnwKpQeza3A\n",
      "✓ Already exists: vo7BYs1OqbM\n",
      "✓ Already exists: vp6p45b-038\n",
      "✓ Already exists: vpU4XIISXtM\n",
      "✓ Already exists: vrMmkVV4SOE\n",
      "✓ Already exists: vrxT5jhqu0Q\n",
      "✓ Already exists: vvfs2TUj-D4\n",
      "✓ Already exists: vx5iuWuE2Ng\n",
      "✓ Already exists: w-YAUcPl-HU\n",
      "✓ Already exists: w2vMywh5Nto\n",
      "✓ Already exists: w3QIsHxQfPE\n",
      "✓ Already exists: w4Z1QuBOMWU\n",
      "✓ Already exists: w5EbmsPfGSo\n",
      "✓ Already exists: w5qf9O6c20o\n",
      "✓ Already exists: w6MtzUCl4vM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] w6zHc6nRJ0o: Video unavailable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading w6zHc6nRJ0o: ERROR: [youtube] w6zHc6nRJ0o: Video unavailable\n",
      "✗ Failed: w6zHc6nRJ0o\n",
      "✓ Already exists: w9CxACZ5Oi0\n",
      "✓ Already exists: w9EGDo9Yybc\n",
      "✓ Already exists: wBozBh7BR6k\n",
      "✓ Already exists: wFTlySgdWX4\n",
      "✓ Already exists: wIP7AqIOU1s\n",
      "✓ Already exists: wKE9STHwX-Q\n",
      "✓ Already exists: wKoFJHb2BoI\n",
      "✓ Already exists: wL4HaT8rEVU\n",
      "✓ Already exists: wMelBK3yArA\n",
      "✓ Already exists: wMi_0eEIpcM\n",
      "✓ Already exists: wQN7fRaPl2A\n",
      "✓ Already exists: wT2Y0DCq5LI\n",
      "✓ Already exists: wXWpkfGfZD8\n",
      "✓ Already exists: wXmIm6Bq3Tc\n",
      "✓ Already exists: wZopmfXTtxw\n",
      "✓ Already exists: w_z9oSn-eIM\n",
      "✓ Already exists: wc4UEh8wvCA\n",
      "✓ Already exists: weJKl-6TiDQ\n",
      "✓ Already exists: wgIf0FX6WzI\n",
      "✓ Already exists: wg_kYW4xvz4\n",
      "✓ Already exists: whIj6mrUGzQ\n",
      "✓ Already exists: whZygh228yw\n",
      "✓ Already exists: woyCm7d2UIM\n",
      "✓ Already exists: wraN7rWUsfI\n",
      "✓ Already exists: wsJ5ZLKiPzs\n",
      "✓ Already exists: wsdH6cv4YkA\n",
      "✓ Already exists: wv6YaiCGPi0\n",
      "✓ Already exists: wz-7sy_Rin4\n",
      "✓ Already exists: x-ob6_6f4jQ\n",
      "✓ Already exists: x1x54MgStxQ\n",
      "✓ Already exists: x6FbyqrK0g0\n",
      "✓ Already exists: xBDcJKb-9vk\n",
      "✓ Already exists: xIdWJyhWueE\n",
      "✓ Already exists: xJMTA3Ay5FI\n",
      "✓ Already exists: xJYBA7VTkHA\n",
      "✓ Already exists: xKEJ6fVhb8w\n",
      "✓ Already exists: xKc_9B3RiOc\n",
      "✓ Already exists: xKrdOZAp2w0\n",
      "✓ Already exists: xL7Krm6FSWE\n",
      "✓ Already exists: xLQF7S41XLE\n",
      "✓ Already exists: xLZp-3_71Vs\n",
      "✓ Already exists: xM4p5pmRAxM\n",
      "✓ Already exists: xN9tKWgXLI4\n",
      "✓ Already exists: xSDkn9PtQm0\n",
      "✓ Already exists: xUVvBF9BWdg\n",
      "✓ Already exists: xb07gLlmkL8\n",
      "✓ Already exists: xeHt-R5ScmI\n",
      "✓ Already exists: xgXd06kKFIQ\n",
      "✓ Already exists: xgwzTQ8vnso\n",
      "✓ Already exists: xl4FJzeU0YA\n",
      "✓ Already exists: xrqDoBor2dk\n",
      "✓ Already exists: xt6V3Ic72nE\n",
      "✓ Already exists: xtGmrLOsjHk\n",
      "✓ Already exists: xuepy6SFOf8\n",
      "✓ Already exists: xuxKtxzq2Cs\n",
      "✓ Already exists: xvryKn-V-JM\n",
      "✓ Already exists: xx1RccwlF5g\n",
      "✓ Already exists: xx3nnVzGXa0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ERROR: ffmpeg exited with code 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading xxCnmao8FAs: ERROR: ffmpeg exited with code 1\n",
      "✗ Failed: xxCnmao8FAs\n",
      "✓ Already exists: xyAbP5XfGz8\n",
      "✓ Already exists: xyXQ7Z1vX7E\n",
      "✓ Already exists: xyco-5DC_K8\n",
      "✓ Already exists: xzgnLpKkvdg\n",
      "✓ Already exists: y0w7FyJcZ8w\n",
      "✓ Already exists: y516mYOT_9c\n",
      "✓ Already exists: y6NS77HLjEE\n",
      "✓ Already exists: y7PtSsbkGdM\n",
      "✓ Already exists: y8gB3-yw3tE\n",
      "✓ Already exists: y8oi64M0IyE\n",
      "✓ Already exists: y9hdu9iMBG8\n",
      "✓ Already exists: yCGM8aJV6fM\n",
      "✓ Already exists: yFh6J72KnCM\n",
      "✓ Already exists: yIOUPSGFqoY\n",
      "✓ Already exists: yKx_RFUTPfI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] yNIZaqTHUnc: Video unavailable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading yNIZaqTHUnc: ERROR: [youtube] yNIZaqTHUnc: Video unavailable\n",
      "✗ Failed: yNIZaqTHUnc\n",
      "✓ Already exists: yO7MWuJ7zLA\n",
      "✓ Already exists: yPou7kokTgA\n",
      "✓ Already exists: yPzhMx3NPW4\n",
      "✓ Already exists: yRU7DifuAXY\n",
      "✓ Already exists: yRWndZvIAHc\n",
      "✓ Already exists: ySY5J3TDgag\n",
      "✓ Already exists: yTc-ENutOD4\n",
      "✓ Already exists: yTq3Kr3jkvs\n",
      "✓ Already exists: yVWk3yq3Abc\n",
      "✓ Already exists: yZNgqVInQGw\n",
      "✓ Already exists: y_lfY0uzmr0\n",
      "✓ Already exists: y_toDfeACWE\n",
      "✓ Already exists: ye6O_T8YuHQ\n",
      "✓ Already exists: yesyhQkYrQM\n",
      "✓ Already exists: yfZ0z1C3blk\n",
      "✓ Already exists: yhS-6Y8ToR8\n",
      "✓ Already exists: yi4-kGV30qs\n",
      "✓ Already exists: yl6LJDi0gi0\n",
      "✓ Already exists: ylKvglDzBU4\n",
      "✓ Already exists: yn4-OtUmyWo\n",
      "✓ Already exists: ynWPvcGXFrM\n",
      "✓ Already exists: ypg2ItQIc2c\n",
      "✓ Already exists: yreWOyWr6Uk\n",
      "✓ Already exists: ywuR9AfpA_E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] yzT9nsHslAk: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading yzT9nsHslAk: ERROR: [youtube] yzT9nsHslAk: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n",
      "✗ Failed: yzT9nsHslAk\n",
      "✓ Already exists: z0w3Y8BGLQE\n",
      "✓ Already exists: z2kTJ6pQ4Uo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] z4ewUsnIJKI: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading z4ewUsnIJKI: ERROR: [youtube] z4ewUsnIJKI: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n",
      "✗ Failed: z4ewUsnIJKI\n",
      "✓ Already exists: z6SNngkMAug\n",
      "✓ Already exists: z7vNtEcM9Bk\n",
      "✓ Already exists: z8Wjdss5uMg\n",
      "✓ Already exists: z9hRQiJMnIw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] zCrpaLEq1VQ: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading zCrpaLEq1VQ: ERROR: [youtube] zCrpaLEq1VQ: Private video. Sign in if you've been granted access to this video. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies. Also see  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies  for tips on effectively exporting YouTube cookies\n",
      "✗ Failed: zCrpaLEq1VQ\n",
      "✓ Already exists: zD4PXuUkwsc\n",
      "✓ Already exists: zGBKakEGSyc\n",
      "✓ Already exists: zGONTDY_rNM\n",
      "✓ Already exists: zNSV9GkpRfM\n",
      "✓ Already exists: zNbF006Y5x4\n",
      "✓ Already exists: zNgRUFOj3HI\n",
      "✓ Already exists: zOvFaef41iw\n",
      "✓ Already exists: zPMiMXCazAI\n",
      "✓ Already exists: zPhuyMYy9EI\n",
      "✓ Already exists: zR4ebAuqy8w\n",
      "✓ Already exists: zRixZ7mWwho\n",
      "✓ Already exists: zU4mwg-HHoQ\n",
      "✓ Already exists: zUaZGKZIKic\n",
      "✓ Already exists: zWJC_qr2610\n",
      "✓ Already exists: zXxJymYt8Z4\n",
      "✓ Already exists: zYM0gtd_PRo\n",
      "✓ Already exists: zYUZEXCE7gw\n",
      "✓ Already exists: z_aUtjxgCNk\n",
      "✓ Already exists: zaEdWwSamS0\n",
      "✓ Already exists: zayC5mUo7sY\n",
      "✓ Already exists: zdtVT2xwrHU\n",
      "✓ Already exists: zfkPKRn8ah8\n",
      "✓ Already exists: zgI-Lr6Pbcs\n",
      "✓ Already exists: zixIuxzCCvs\n",
      "✓ Already exists: zjsWFvUkh7M\n",
      "✓ Already exists: zopos1B6Elc\n",
      "✓ Already exists: zrrM6Qg2Dwg\n",
      "✓ Already exists: ztfegVzqeCI\n",
      "✓ Already exists: zwfo7wnXdjs\n",
      "✓ Already exists: zx_vcwOsDO4\n",
      "✓ Already exists: zzNdwF40ID8\n",
      "\n",
      "=== Download Summary ===\n",
      "Successfully downloaded: 957\n",
      "Failed: 43\n",
      "Successfully downloaded: 957\n",
      "Failed: 43\n",
      "\n",
      "Creating archetype training data...\n",
      "\n",
      "=== Archetype Distribution Statistics ===\n",
      "\n",
      "SINE:\n",
      "  Mean weight: 0.397\n",
      "  Std dev: 0.382\n",
      "  Max weight: 1.000\n",
      "  % samples with weight > 0.3: 45.0%\n",
      "\n",
      "SQUARE:\n",
      "  Mean weight: 0.152\n",
      "  Std dev: 0.271\n",
      "  Max weight: 1.000\n",
      "  % samples with weight > 0.3: 16.1%\n",
      "\n",
      "SAWTOOTH:\n",
      "  Mean weight: 0.188\n",
      "  Std dev: 0.291\n",
      "  Max weight: 1.000\n",
      "  % samples with weight > 0.3: 21.0%\n",
      "\n",
      "TRIANGLE:\n",
      "  Mean weight: 0.147\n",
      "  Std dev: 0.249\n",
      "  Max weight: 1.000\n",
      "  % samples with weight > 0.3: 14.5%\n",
      "\n",
      "NOISE:\n",
      "  Mean weight: 0.115\n",
      "  Std dev: 0.222\n",
      "  Max weight: 1.000\n",
      "  % samples with weight > 0.3: 11.8%\n",
      "\n",
      "=== Examples with Dominant Archetypes ===\n",
      "\n",
      "SINE dominant (1.00):\n",
      "  Description: A male vocalist sings this soft love song. The tempo is slow with a romantic piano accompaniment, gr...\n",
      "  Vector: ['1.00', '0.00', '0.00', '0.00', '0.00']\n",
      "\n",
      "SQUARE dominant (1.00):\n",
      "  Description: Spirited Christmas music with a fast four on the floor dance beat. There is a high pitched 'chipmunk...\n",
      "  Vector: ['0.00', '1.00', '0.00', '0.00', '0.00']\n",
      "\n",
      "SAWTOOTH dominant (1.00):\n",
      "  Description: A male singer sings this beautiful melody with backup singers in vocal harmony. The song is medium t...\n",
      "  Vector: ['0.00', '0.00', '1.00', '0.00', '0.00']\n",
      "\n",
      "TRIANGLE dominant (1.00):\n",
      "  Description: The R&B music features a male voice singing and being backed by similar male voices from time to tim...\n",
      "  Vector: ['0.00', '0.00', '0.00', '1.00', '0.00']\n",
      "\n",
      "NOISE dominant (1.00):\n",
      "  Description: This is an opera song that's recorded at a very low quality. The vocal audio is distorted and create...\n",
      "  Vector: ['0.00', '0.00', '0.00', '0.00', '1.00']\n",
      "\n",
      "Dataset split:\n",
      "  Train: 669 samples (70.0%)\n",
      "  Val:   143 samples (15.0%)\n",
      "  Test:  145 samples (15.0%)\n",
      "\n",
      "✓ Saved train set: musiccaps_training_data_train.npz\n",
      "✓ Saved val set: musiccaps_training_data_val.npz\n",
      "✓ Saved test set: musiccaps_training_data_test.npz\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Prepare dataset (run once)\n",
    "print(\"Step 1: Preparing MusicCaps dataset with train/val/test split...\")\n",
    "train_data_path, val_data_path, test_data_path = prepare_musiccaps_data(\n",
    "    csv_path=csv_path,\n",
    "    audio_dir='musiccaps_audio',\n",
    "    max_downloads=config['max_downloads'],\n",
    "    train_split=0.7,\n",
    "    val_split=0.15,\n",
    "    test_split=0.15,\n",
    "    random_seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2: Creating PyTorch datasets...\n",
      "Loading training data from musiccaps_training_data_train.npz\n",
      "Loaded 669 training examples\n",
      "Found 669 samples with valid audio files\n",
      "Loading training data from musiccaps_training_data_val.npz\n",
      "Loaded 143 training examples\n",
      "Found 143 samples with valid audio files\n",
      "Loading training data from musiccaps_training_data_test.npz\n",
      "Loaded 145 training examples\n",
      "Found 145 samples with valid audio files\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create datasets\n",
    "print(\"\\nStep 2: Creating PyTorch datasets...\")\n",
    "train_dataset = MusicCapsDataset(\n",
    "    train_data_path,\n",
    "    sample_rate=config['sample_rate'],\n",
    "    audio_duration=config['audio_duration'],\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "val_dataset = MusicCapsDataset(\n",
    "    val_data_path,\n",
    "    sample_rate=config['sample_rate'],\n",
    "    audio_duration=config['audio_duration'],\n",
    "    augment=False\n",
    ")\n",
    "\n",
    "test_dataset = MusicCapsDataset(\n",
    "    test_data_path,\n",
    "    sample_rate=config['sample_rate'],\n",
    "    audio_duration=config['audio_duration'],\n",
    "    augment=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Reload the modules to pick up changes\n",
    "import importlib\n",
    "import text_tower\n",
    "import lstmabar_model\n",
    "\n",
    "importlib.reload(text_tower)\n",
    "importlib.reload(lstmabar_model)\n",
    "\n",
    "# Re-import the classes\n",
    "from text_tower import TextEncoder\n",
    "from lstmabar_model import LSTMABAR, LSTMABARTrainer\n",
    "from improved_text_encoders import ImprovedTextEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Initializing LSTMABAR model...\n",
      "Loading text encoder: sentence-transformers/all-MiniLM-L6-v2\n",
      "Loading improved text encoder: sentence-transformers/all-mpnet-base-v2\n",
      "Model has 128,403,725 parameters\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Initialize model\n",
    "print(\"\\nStep 3: Initializing LSTMABAR model...\")\n",
    "model = LSTMABAR(\n",
    "    embedding_dim=config['embedding_dim'],\n",
    "    audio_architecture=config['audio_architecture'],\n",
    "    sample_rate=config['sample_rate'],\n",
    "    use_quantum_attention=False,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Approach C Better base model\n",
    "model.text_encoder = ImprovedTextEncoder(\n",
    "    model_name='sentence-transformers/all-mpnet-base-v2',\n",
    "    embedding_dim=768,\n",
    "    projection_depth='deep',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"Model has {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach C. Do this or A or B, not all 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 6,233,091\n"
     ]
    }
   ],
   "source": [
    "# Step 4C: Configure freezing (Approach A style)\n",
    "\n",
    "# Freeze everything except projection and contrastive\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# Unfreeze projection\n",
    "for p in model.text_encoder.projection.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "# Unfreeze contrastive module\n",
    "if hasattr(model, 'contrastive_module'):\n",
    "    for p in model.contrastive_module.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "print(f\"Trainable params: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pipeline initialized:\n",
      "  Training samples: 669\n",
      "  Validation samples: 143\n",
      "  Batch size: 32\n",
      "  Total epochs: 30\n",
      "  Steps per epoch: 21\n",
      "\n",
      "============================================================\n",
      "Epoch 1/30\n",
      "============================================================\n",
      "Epoch 0, Batch 0/21: Loss=2.4596, Contrastive=3.4719, Archetype=0.1002\n",
      "Epoch 0, Batch 10/21: Loss=2.4557, Contrastive=3.4575, Archetype=0.1232\n",
      "Epoch 0, Batch 20/21: Loss=2.3849, Contrastive=3.3693, Archetype=0.0926\n",
      "\n",
      "Train Losses: {'total': np.float64(2.4606422129131498), 'contrastive': np.float64(3.47143208412897), 'archetype': np.float64(0.10547633540062677)}\n",
      "Val Losses: {'total': 2.351073884963989, 'contrastive': 3.3214312553405763, 'archetype': 0.08572169691324234}\n",
      "Checkpoint saved to checkpoints/improved_approach_c/best_model.pth\n",
      "✓ Best model saved (val_loss: 2.3511)\n",
      "\n",
      "============================================================\n",
      "Epoch 2/30\n",
      "============================================================\n",
      "Epoch 1, Batch 0/21: Loss=2.4647, Contrastive=3.4699, Archetype=0.1237\n",
      "Epoch 1, Batch 10/21: Loss=2.4388, Contrastive=3.4383, Archetype=0.1121\n",
      "Epoch 1, Batch 20/21: Loss=2.3687, Contrastive=3.3383, Archetype=0.1120\n",
      "\n",
      "Train Losses: {'total': np.float64(2.421911591575259), 'contrastive': np.float64(3.4166487966265), 'archetype': np.float64(0.10350376828795388)}\n",
      "Val Losses: {'total': 2.278098964691162, 'contrastive': 3.21757173538208, 'archetype': 0.08435129821300506}\n",
      "Checkpoint saved to checkpoints/improved_approach_c/best_model.pth\n",
      "✓ Best model saved (val_loss: 2.2781)\n",
      "\n",
      "============================================================\n",
      "Epoch 3/30\n",
      "============================================================\n",
      "Epoch 2, Batch 0/21: Loss=2.4098, Contrastive=3.3974, Archetype=0.1078\n",
      "Epoch 2, Batch 10/21: Loss=2.2588, Contrastive=3.1776, Archetype=0.1171\n",
      "Epoch 2, Batch 20/21: Loss=2.1979, Contrastive=3.0939, Archetype=0.1108\n",
      "\n",
      "Train Losses: {'total': np.float64(2.3441641444251653), 'contrastive': np.float64(3.306361368724278), 'archetype': np.float64(0.10077371732110069)}\n",
      "Val Losses: {'total': 2.244702196121216, 'contrastive': 3.1701210021972654, 'archetype': 0.08344011157751083}\n",
      "Checkpoint saved to checkpoints/improved_approach_c/best_model.pth\n",
      "✓ Best model saved (val_loss: 2.2447)\n",
      "\n",
      "============================================================\n",
      "Epoch 4/30\n",
      "============================================================\n",
      "Epoch 3, Batch 0/21: Loss=2.3193, Contrastive=3.2683, Archetype=0.1070\n",
      "Epoch 3, Batch 10/21: Loss=2.2615, Contrastive=3.1802, Archetype=0.1226\n",
      "Epoch 3, Batch 20/21: Loss=2.2608, Contrastive=3.1900, Archetype=0.0943\n",
      "\n",
      "Train Losses: {'total': np.float64(2.2845816839308966), 'contrastive': np.float64(3.220851954959688), 'archetype': np.float64(0.10217522652376265)}\n",
      "Val Losses: {'total': 2.2210253953933714, 'contrastive': 3.136237621307373, 'archetype': 0.08364832550287246}\n",
      "Checkpoint saved to checkpoints/improved_approach_c/best_model.pth\n",
      "✓ Best model saved (val_loss: 2.2210)\n",
      "\n",
      "============================================================\n",
      "Epoch 5/30\n",
      "============================================================\n",
      "Epoch 4, Batch 0/21: Loss=2.2001, Contrastive=3.0986, Archetype=0.1077\n",
      "Epoch 4, Batch 10/21: Loss=2.2360, Contrastive=3.1458, Archetype=0.1174\n",
      "Epoch 4, Batch 20/21: Loss=2.2156, Contrastive=3.1252, Archetype=0.0929\n",
      "\n",
      "Train Losses: {'total': np.float64(2.230294488725208), 'contrastive': np.float64(3.143684398560297), 'archetype': np.float64(0.1008237653544971)}\n",
      "Val Losses: {'total': 2.2161365747451782, 'contrastive': 3.128753662109375, 'archetype': 0.0853982612490654}\n",
      "Checkpoint saved to checkpoints/improved_approach_c/best_model.pth\n",
      "✓ Best model saved (val_loss: 2.2161)\n",
      "\n",
      "============================================================\n",
      "Epoch 6/30\n",
      "============================================================\n",
      "Epoch 5, Batch 0/21: Loss=2.1944, Contrastive=3.0922, Archetype=0.1008\n",
      "Epoch 5, Batch 10/21: Loss=2.2112, Contrastive=3.1191, Archetype=0.0952\n",
      "Epoch 5, Batch 20/21: Loss=2.1904, Contrastive=3.0845, Archetype=0.1073\n",
      "\n",
      "Train Losses: {'total': np.float64(2.2158457665216353), 'contrastive': np.float64(3.123362348193214), 'archetype': np.float64(0.09970734445821672)}\n",
      "Val Losses: {'total': 2.230677676200867, 'contrastive': 3.150158166885376, 'archetype': 0.08318638801574707}\n",
      "\n",
      "============================================================\n",
      "Epoch 7/30\n",
      "============================================================\n",
      "Epoch 6, Batch 0/21: Loss=2.1979, Contrastive=3.0928, Archetype=0.1098\n",
      "Epoch 6, Batch 10/21: Loss=2.1906, Contrastive=3.0927, Archetype=0.0872\n",
      "Epoch 6, Batch 20/21: Loss=2.1130, Contrastive=2.9779, Archetype=0.0967\n",
      "\n",
      "Train Losses: {'total': np.float64(2.1730168660481772), 'contrastive': np.float64(3.0622272945585705), 'archetype': np.float64(0.09953528749091285)}\n",
      "Val Losses: {'total': 2.196192479133606, 'contrastive': 3.100702238082886, 'archetype': 0.08385737240314484}\n",
      "Checkpoint saved to checkpoints/improved_approach_c/best_model.pth\n",
      "✓ Best model saved (val_loss: 2.1962)\n",
      "\n",
      "============================================================\n",
      "Epoch 8/30\n",
      "============================================================\n",
      "Epoch 7, Batch 0/21: Loss=2.1729, Contrastive=3.0558, Archetype=0.1151\n",
      "Epoch 7, Batch 10/21: Loss=2.1726, Contrastive=3.0595, Archetype=0.1033\n",
      "Epoch 7, Batch 20/21: Loss=2.0388, Contrastive=2.8703, Archetype=0.0963\n",
      "\n",
      "Train Losses: {'total': np.float64(2.1532820406414213), 'contrastive': np.float64(3.034194514864967), 'archetype': np.float64(0.0989430777373768)}\n",
      "Val Losses: {'total': 2.226142334938049, 'contrastive': 3.143964385986328, 'archetype': 0.08218982219696044}\n",
      "\n",
      "============================================================\n",
      "Epoch 9/30\n",
      "============================================================\n",
      "Epoch 8, Batch 0/21: Loss=2.1430, Contrastive=3.0218, Archetype=0.0926\n",
      "Epoch 8, Batch 10/21: Loss=2.1607, Contrastive=3.0437, Archetype=0.1003\n",
      "Epoch 8, Batch 20/21: Loss=2.0150, Contrastive=2.8414, Archetype=0.0858\n",
      "\n",
      "Train Losses: {'total': np.float64(2.1432549499330067), 'contrastive': np.float64(3.0195978596096946), 'archetype': np.float64(0.09994317591190338)}\n",
      "Val Losses: {'total': 2.206076717376709, 'contrastive': 3.1151055335998534, 'archetype': 0.08286800235509872}\n",
      "\n",
      "============================================================\n",
      "Epoch 10/30\n",
      "============================================================\n",
      "Epoch 9, Batch 0/21: Loss=2.0492, Contrastive=2.8867, Archetype=0.0938\n",
      "Epoch 9, Batch 10/21: Loss=2.1866, Contrastive=3.0853, Archetype=0.0891\n",
      "Epoch 9, Batch 20/21: Loss=1.9857, Contrastive=2.7897, Archetype=0.1118\n",
      "\n",
      "Train Losses: {'total': np.float64(2.1302884760357084), 'contrastive': np.float64(3.0008083411625455), 'archetype': np.float64(0.10082463671763738)}\n",
      "Val Losses: {'total': 2.225911569595337, 'contrastive': 3.143219470977783, 'archetype': 0.08364319354295731}\n",
      "Checkpoint saved to checkpoints/improved_approach_c/checkpoint_epoch_10.pth\n",
      "\n",
      "============================================================\n",
      "Epoch 11/30\n",
      "============================================================\n",
      "Epoch 10, Batch 0/21: Loss=2.1804, Contrastive=3.0729, Archetype=0.0997\n",
      "Epoch 10, Batch 10/21: Loss=2.0714, Contrastive=2.9232, Archetype=0.0860\n",
      "Epoch 10, Batch 20/21: Loss=1.9534, Contrastive=2.7503, Archetype=0.0898\n",
      "\n",
      "Train Losses: {'total': np.float64(2.1220661061150685), 'contrastive': np.float64(2.989639634177798), 'archetype': np.float64(0.09881571396475747)}\n",
      "Val Losses: {'total': 2.218230652809143, 'contrastive': 3.1322677612304686, 'archetype': 0.08356919437646866}\n",
      "\n",
      "============================================================\n",
      "Epoch 12/30\n",
      "============================================================\n",
      "Epoch 11, Batch 0/21: Loss=2.0395, Contrastive=2.8689, Archetype=0.1042\n",
      "Epoch 11, Batch 10/21: Loss=1.9794, Contrastive=2.7966, Archetype=0.0724\n",
      "Epoch 11, Batch 20/21: Loss=2.1029, Contrastive=2.9618, Archetype=0.1000\n",
      "\n",
      "Train Losses: {'total': np.float64(2.0812612771987915), 'contrastive': np.float64(2.9311712355840776), 'archetype': np.float64(0.09943633987790063)}\n",
      "Val Losses: {'total': 2.210126495361328, 'contrastive': 3.120203447341919, 'archetype': 0.08527369052171707}\n",
      "\n",
      "============================================================\n",
      "Epoch 13/30\n",
      "============================================================\n",
      "Epoch 12, Batch 0/21: Loss=2.0667, Contrastive=2.9045, Archetype=0.1131\n",
      "Epoch 12, Batch 10/21: Loss=2.1785, Contrastive=3.0671, Archetype=0.1071\n",
      "Epoch 12, Batch 20/21: Loss=2.0078, Contrastive=2.8278, Archetype=0.0976\n",
      "\n",
      "Train Losses: {'total': np.float64(2.079381431852068), 'contrastive': np.float64(2.928856157121204), 'archetype': np.float64(0.0981530901931581)}\n",
      "Val Losses: {'total': 2.21255738735199, 'contrastive': 3.1237481117248533, 'archetype': 0.08502260446548462}\n",
      "\n",
      "============================================================\n",
      "Epoch 14/30\n",
      "============================================================\n",
      "Epoch 13, Batch 0/21: Loss=2.1290, Contrastive=3.0027, Archetype=0.0908\n",
      "Epoch 13, Batch 10/21: Loss=2.0688, Contrastive=2.9101, Archetype=0.1043\n",
      "Epoch 13, Batch 20/21: Loss=1.9591, Contrastive=2.7533, Archetype=0.1071\n",
      "\n",
      "Train Losses: {'total': np.float64(2.0630051635560536), 'contrastive': np.float64(2.9049602236066545), 'archetype': np.float64(0.09989291145688012)}\n",
      "Val Losses: {'total': 2.203902816772461, 'contrastive': 3.11128625869751, 'archetype': 0.08536585420370102}\n",
      "\n",
      "============================================================\n",
      "Epoch 15/30\n",
      "============================================================\n",
      "Epoch 14, Batch 0/21: Loss=2.0706, Contrastive=2.9127, Archetype=0.1067\n",
      "Epoch 14, Batch 10/21: Loss=2.0012, Contrastive=2.8216, Archetype=0.0879\n",
      "Epoch 14, Batch 20/21: Loss=1.9868, Contrastive=2.7938, Archetype=0.1029\n",
      "\n",
      "Train Losses: {'total': np.float64(2.052226946467445), 'contrastive': np.float64(2.890047788619995), 'archetype': np.float64(0.09818609449125472)}\n",
      "Val Losses: {'total': 2.21343309879303, 'contrastive': 3.125412845611572, 'archetype': 0.0835746631026268}\n",
      "\n",
      "============================================================\n",
      "Epoch 16/30\n",
      "============================================================\n",
      "Epoch 15, Batch 0/21: Loss=2.1165, Contrastive=2.9888, Archetype=0.0797\n",
      "Epoch 15, Batch 10/21: Loss=2.1121, Contrastive=2.9737, Archetype=0.1038\n",
      "Epoch 15, Batch 20/21: Loss=1.9467, Contrastive=2.7355, Archetype=0.1078\n",
      "\n",
      "Train Losses: {'total': np.float64(2.067728281021118), 'contrastive': np.float64(2.9124038105919245), 'archetype': np.float64(0.0974502084510667)}\n",
      "Val Losses: {'total': 2.204452109336853, 'contrastive': 3.1125369548797606, 'archetype': 0.08373543471097947}\n",
      "\n",
      "============================================================\n",
      "Epoch 17/30\n",
      "============================================================\n",
      "Epoch 16, Batch 0/21: Loss=1.9503, Contrastive=2.7377, Archetype=0.1163\n",
      "Epoch 16, Batch 10/21: Loss=2.0097, Contrastive=2.8418, Archetype=0.0685\n",
      "Epoch 16, Batch 20/21: Loss=1.9933, Contrastive=2.8053, Archetype=0.1011\n",
      "\n",
      "Train Losses: {'total': np.float64(2.0349812167031422), 'contrastive': np.float64(2.865430162066505), 'archetype': np.float64(0.09813728751171202)}\n",
      "Val Losses: {'total': 2.1866703271865844, 'contrastive': 3.0866907119750975, 'archetype': 0.08528768867254258}\n",
      "Checkpoint saved to checkpoints/improved_approach_c/best_model.pth\n",
      "✓ Best model saved (val_loss: 2.1867)\n",
      "\n",
      "============================================================\n",
      "Epoch 18/30\n",
      "============================================================\n",
      "Epoch 17, Batch 0/21: Loss=2.0406, Contrastive=2.8695, Archetype=0.1090\n",
      "Epoch 17, Batch 10/21: Loss=2.1083, Contrastive=2.9639, Archetype=0.1135\n",
      "Epoch 17, Batch 20/21: Loss=1.7969, Contrastive=2.5228, Archetype=0.1025\n",
      "\n",
      "Train Losses: {'total': np.float64(2.019643607593718), 'contrastive': np.float64(2.8425298985980807), 'archetype': np.float64(0.10158231073901766)}\n",
      "Val Losses: {'total': 2.196215844154358, 'contrastive': 3.1000757694244383, 'archetype': 0.08616695106029511}\n",
      "\n",
      "============================================================\n",
      "Epoch 19/30\n",
      "============================================================\n",
      "Epoch 18, Batch 0/21: Loss=1.9480, Contrastive=2.7374, Archetype=0.1027\n",
      "Epoch 18, Batch 10/21: Loss=1.9938, Contrastive=2.8035, Archetype=0.1078\n",
      "Epoch 18, Batch 20/21: Loss=2.0454, Contrastive=2.8728, Archetype=0.1151\n",
      "\n",
      "Train Losses: {'total': np.float64(2.017510697955177), 'contrastive': np.float64(2.840425343740554), 'archetype': np.float64(0.09827745599406106)}\n",
      "Val Losses: {'total': 2.226138114929199, 'contrastive': 3.1432881355285645, 'archetype': 0.0845348060131073}\n",
      "\n",
      "============================================================\n",
      "Epoch 20/30\n",
      "============================================================\n",
      "Epoch 19, Batch 0/21: Loss=1.9132, Contrastive=2.6924, Archetype=0.0979\n",
      "Epoch 19, Batch 10/21: Loss=1.9960, Contrastive=2.8079, Archetype=0.1055\n",
      "Epoch 19, Batch 20/21: Loss=1.9761, Contrastive=2.7812, Archetype=0.0963\n",
      "\n",
      "Train Losses: {'total': np.float64(1.9834051245734805), 'contrastive': np.float64(2.7914133980160667), 'archetype': np.float64(0.09930690768219176)}\n",
      "Val Losses: {'total': 2.22216260433197, 'contrastive': 3.137640857696533, 'archetype': 0.0844240128993988}\n",
      "Checkpoint saved to checkpoints/improved_approach_c/checkpoint_epoch_20.pth\n",
      "\n",
      "============================================================\n",
      "Epoch 21/30\n",
      "============================================================\n",
      "Epoch 20, Batch 0/21: Loss=2.0892, Contrastive=2.9420, Archetype=0.1021\n",
      "Epoch 20, Batch 10/21: Loss=1.9699, Contrastive=2.7684, Archetype=0.1085\n",
      "Epoch 20, Batch 20/21: Loss=1.9418, Contrastive=2.7329, Archetype=0.0972\n",
      "\n",
      "Train Losses: {'total': np.float64(1.9993372474397932), 'contrastive': np.float64(2.814339967001052), 'archetype': np.float64(0.0987367509376435)}\n",
      "Val Losses: {'total': 2.218421292304993, 'contrastive': 3.132300281524658, 'archetype': 0.08440719544887543}\n",
      "\n",
      "============================================================\n",
      "Epoch 22/30\n",
      "============================================================\n",
      "Epoch 21, Batch 0/21: Loss=2.0147, Contrastive=2.8346, Archetype=0.1005\n",
      "Epoch 21, Batch 10/21: Loss=1.9462, Contrastive=2.7436, Archetype=0.0869\n",
      "Epoch 21, Batch 20/21: Loss=1.9168, Contrastive=2.7039, Archetype=0.0807\n",
      "\n",
      "Train Losses: {'total': np.float64(1.983184121903919), 'contrastive': np.float64(2.7915769872211276), 'archetype': np.float64(0.09766858142046701)}\n",
      "Val Losses: {'total': 2.22043776512146, 'contrastive': 3.1357428550720217, 'archetype': 0.08244349360466004}\n",
      "\n",
      "============================================================\n",
      "Epoch 23/30\n",
      "============================================================\n",
      "Epoch 22, Batch 0/21: Loss=2.0324, Contrastive=2.8689, Archetype=0.0823\n",
      "Epoch 22, Batch 10/21: Loss=1.9832, Contrastive=2.7946, Archetype=0.0886\n",
      "Epoch 22, Batch 20/21: Loss=1.9075, Contrastive=2.6826, Archetype=0.1017\n",
      "\n",
      "Train Losses: {'total': np.float64(1.9636655648549397), 'contrastive': np.float64(2.7635445027124312), 'archetype': np.float64(0.09816719769012361)}\n",
      "Val Losses: {'total': 2.2144001960754394, 'contrastive': 3.1265446186065673, 'archetype': 0.08444778323173523}\n",
      "\n",
      "============================================================\n",
      "Epoch 24/30\n",
      "============================================================\n",
      "Epoch 23, Batch 0/21: Loss=1.8654, Contrastive=2.6217, Archetype=0.1014\n",
      "Epoch 23, Batch 10/21: Loss=1.9860, Contrastive=2.7959, Archetype=0.0973\n",
      "Epoch 23, Batch 20/21: Loss=1.9391, Contrastive=2.7316, Archetype=0.0911\n",
      "\n",
      "Train Losses: {'total': np.float64(1.9563810030619304), 'contrastive': np.float64(2.7530164491562616), 'archetype': np.float64(0.09861693353880019)}\n",
      "Val Losses: {'total': 2.2141559600830076, 'contrastive': 3.1265369415283204, 'archetype': 0.0832530528306961}\n",
      "\n",
      "============================================================\n",
      "Epoch 25/30\n",
      "============================================================\n",
      "Epoch 24, Batch 0/21: Loss=1.7876, Contrastive=2.5226, Archetype=0.0728\n",
      "Epoch 24, Batch 10/21: Loss=1.9445, Contrastive=2.7434, Archetype=0.0778\n",
      "Epoch 24, Batch 20/21: Loss=1.9824, Contrastive=2.7865, Archetype=0.1083\n",
      "\n",
      "Train Losses: {'total': np.float64(1.9584021852129982), 'contrastive': np.float64(2.7560442629314603), 'archetype': np.float64(0.09807597987708591)}\n",
      "Val Losses: {'total': 2.2185253620147707, 'contrastive': 3.1326928615570067, 'archetype': 0.08355481922626495}\n",
      "\n",
      "============================================================\n",
      "Epoch 26/30\n",
      "============================================================\n",
      "Epoch 25, Batch 0/21: Loss=1.9016, Contrastive=2.6748, Archetype=0.0983\n",
      "Epoch 25, Batch 10/21: Loss=2.0246, Contrastive=2.8540, Archetype=0.0916\n",
      "Epoch 25, Batch 20/21: Loss=1.9388, Contrastive=2.7298, Archetype=0.0956\n",
      "\n",
      "Train Losses: {'total': np.float64(1.9563103800728208), 'contrastive': np.float64(2.753085102353777), 'archetype': np.float64(0.09800460154101961)}\n",
      "Val Losses: {'total': 2.220832896232605, 'contrastive': 3.1359507560729982, 'archetype': 0.083689846098423}\n",
      "\n",
      "============================================================\n",
      "Epoch 27/30\n",
      "============================================================\n",
      "Epoch 26, Batch 0/21: Loss=1.9428, Contrastive=2.7308, Archetype=0.1059\n",
      "Epoch 26, Batch 10/21: Loss=1.9858, Contrastive=2.7887, Archetype=0.1140\n",
      "Epoch 26, Batch 20/21: Loss=1.9366, Contrastive=2.7315, Archetype=0.0809\n",
      "\n",
      "Train Losses: {'total': np.float64(1.9509669372013636), 'contrastive': np.float64(2.745341732388451), 'archetype': np.float64(0.09839574850740887)}\n",
      "Val Losses: {'total': 2.1973127126693726, 'contrastive': 3.1019944667816164, 'archetype': 0.08493699431419373}\n",
      "\n",
      "============================================================\n",
      "Epoch 28/30\n",
      "============================================================\n",
      "Epoch 27, Batch 0/21: Loss=1.8894, Contrastive=2.6574, Archetype=0.1005\n",
      "Epoch 27, Batch 10/21: Loss=1.9404, Contrastive=2.7346, Archetype=0.0857\n",
      "Epoch 27, Batch 20/21: Loss=1.8817, Contrastive=2.6448, Archetype=0.1028\n",
      "\n",
      "Train Losses: {'total': np.float64(1.9266664130347115), 'contrastive': np.float64(2.7109013398488364), 'archetype': np.float64(0.09742347186519987)}\n",
      "Val Losses: {'total': 2.212115025520325, 'contrastive': 3.1232760906219483, 'archetype': 0.08446152359247208}\n",
      "\n",
      "============================================================\n",
      "Epoch 29/30\n",
      "============================================================\n",
      "Epoch 28, Batch 0/21: Loss=1.9380, Contrastive=2.7257, Archetype=0.0979\n",
      "Epoch 28, Batch 10/21: Loss=1.8204, Contrastive=2.5655, Archetype=0.0841\n",
      "Epoch 28, Batch 20/21: Loss=1.8911, Contrastive=2.6589, Archetype=0.0991\n",
      "\n",
      "Train Losses: {'total': np.float64(1.9198558387302218), 'contrastive': np.float64(2.701401494798206), 'archetype': np.float64(0.09661084910233815)}\n",
      "Val Losses: {'total': 2.2158969402313233, 'contrastive': 3.1284366130828856, 'archetype': 0.08530989587306977}\n",
      "\n",
      "============================================================\n",
      "Epoch 30/30\n",
      "============================================================\n",
      "Epoch 29, Batch 0/21: Loss=1.9321, Contrastive=2.7190, Archetype=0.0979\n",
      "Epoch 29, Batch 10/21: Loss=1.8955, Contrastive=2.6628, Archetype=0.1051\n",
      "Epoch 29, Batch 20/21: Loss=1.8929, Contrastive=2.6552, Archetype=0.1135\n",
      "\n",
      "Train Losses: {'total': np.float64(1.9031970103581746), 'contrastive': np.float64(2.676830541519892), 'archetype': np.float64(0.0992560734351476)}\n",
      "Val Losses: {'total': 2.2416390657424925, 'contrastive': 3.16536808013916, 'archetype': 0.08476193845272065}\n",
      "Checkpoint saved to checkpoints/improved_approach_c/checkpoint_epoch_30.pth\n",
      "\n",
      "============================================================\n",
      "Training complete!\n",
      "============================================================\n",
      "Checkpoint saved to checkpoints/improved_approach_c/final_model.pth\n",
      "Training history plot saved to checkpoints/improved_approach_c/training_history.png\n"
     ]
    }
   ],
   "source": [
    "# Step 5C: Train!\n",
    "\n",
    "# Set checkpoint directory\n",
    "checkpoint_dir = Path(\"checkpoints/improved_approach_c\")\n",
    "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = TrainingPipeline(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    learning_rate=config['learning_rate'],\n",
    "    num_epochs=config['num_epochs'],\n",
    "    checkpoint_dir=checkpoint_dir\n",
    ")\n",
    "\n",
    "# Train\n",
    "pipeline.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do not do both A approach and B approach, just choose one or the other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning approach A: Use Step 4A, Step 4 and then 5A. DO NOT RUN BOTH 5 AND 5A!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters (total): 1,806,338\n",
      " - text projection: 887,808\n",
      " - contrastive module: 918,530\n"
     ]
    }
   ],
   "source": [
    "# Step 4A: Fine-tuning  Approach A (Projection-only)\n",
    "\n",
    "# 1) Freeze everything by default\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# 2) Unfreeze ONLY the text projection head\n",
    "assert hasattr(model, \"text_encoder\") and hasattr(model.text_encoder, \"projection\"), \\\n",
    "    \"Expected model.text_encoder.projection to exist.\"\n",
    "for p in model.text_encoder.projection.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "# 3) Keep contrastive module trainable (e.g., temperature)\n",
    "if hasattr(model, \"contrastive_module\"):\n",
    "    for p in model.contrastive_module.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "# 4) Sanity check: count trainable params\n",
    "def _count_trainable(m): \n",
    "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "\n",
    "total_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters (total): {total_trainable:,}\")\n",
    "print(f\" - text projection: {_count_trainable(model.text_encoder.projection):,}\")\n",
    "if hasattr(model, \"contrastive_module\"):\n",
    "    print(f\" - contrastive module: {_count_trainable(model.contrastive_module):,}\")\n",
    "\n",
    "# 5) Use a slightly higher LR for this phase (TrainingPipeline passes this to LSTMABARTrainer)\n",
    "config['learning_rate'] = 5e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning approach B: Use Step 4B, Step 4 and then 5B. DO NOT RUN BOTH 5 AND 5B!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters (total): 5,355,266\n",
      " - text projection: 887,808\n",
      " - text backbone (last 2 layers): 3,548,928\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "class HFBackboneTextEncoder(nn.Module):\n",
    "    def __init__(self, model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "                 embedding_dim=768, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.backbone = AutoModel.from_pretrained(model_name)  # MiniLM\n",
    "        self.base_dim = self.backbone.config.hidden_size\n",
    "\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(self.base_dim, embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "            nn.LayerNorm(embedding_dim),\n",
    "        )\n",
    "        self.to(device)\n",
    "\n",
    "    def _mean_pool(self, token_embeddings, attention_mask):\n",
    "        mask = attention_mask.unsqueeze(-1).float()\n",
    "        summed = (token_embeddings * mask).sum(dim=1)\n",
    "        denom = mask.sum(dim=1).clamp(min=1e-6)\n",
    "        return summed / denom\n",
    "\n",
    "    def forward(self, texts):\n",
    "        tokens = self.tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(self.device)\n",
    "        outputs = self.backbone(**tokens)                     # [B, T, H]\n",
    "        pooled = self._mean_pool(outputs.last_hidden_state, tokens.attention_mask)  # [B, H]\n",
    "        emb = self.projection(pooled)                         # [B, D]\n",
    "        return F.normalize(emb, p=2, dim=1)\n",
    "\n",
    "# 1) Swap the model's text encoder with the HF-backbone version\n",
    "model.text_encoder = HFBackboneTextEncoder(\n",
    "    model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "    embedding_dim=config['embedding_dim'],\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# 2) Freeze everything first\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# 3) Unfreeze ONLY the last 2 transformer blocks + the projection head\n",
    "# MiniLM-L6 has encoder.layer.0 ... encoder.layer.5; we unfreeze 4 and 5\n",
    "for name, p in model.text_encoder.backbone.named_parameters():\n",
    "    if name.startswith(\"encoder.layer.4\") or name.startswith(\"encoder.layer.5\"):\n",
    "        p.requires_grad = True\n",
    "\n",
    "for p in model.text_encoder.projection.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "# Keep contrastive temperature learnable\n",
    "if hasattr(model, \"contrastive_module\"):\n",
    "    for p in model.contrastive_module.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "# 4) Sanity: print trainable counts\n",
    "def _count_trainable(m): \n",
    "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "\n",
    "total_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters (total): {total_trainable:,}\")\n",
    "print(f\" - text projection: {_count_trainable(model.text_encoder.projection):,}\")\n",
    "\n",
    "# Count unfrozen backbone params\n",
    "bb_trainable = 0\n",
    "for n, p in model.text_encoder.backbone.named_parameters():\n",
    "    if p.requires_grad: bb_trainable += p.numel()\n",
    "print(f\" - text backbone (last 2 layers): {bb_trainable:,}\")\n",
    "\n",
    "# 5) Use a conservative LR for backbone tuning (single LR, trainer builds the optimizer)\n",
    "config['learning_rate'] = 1e-4\n",
    "\n",
    "# 6) Write to a separate checkpoint folder to avoid overwriting\n",
    "from pathlib import Path\n",
    "ckpt_dir_B = Path(\"checkpoints/fine_tune_B\")\n",
    "ckpt_dir_B.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Setting up training pipeline...\n",
      "Training pipeline initialized:\n",
      "  Training samples: 669\n",
      "  Validation samples: 143\n",
      "  Batch size: 16\n",
      "  Total epochs: 20\n",
      "  Steps per epoch: 42\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Create training pipeline\n",
    "print(\"\\nStep 4: Setting up training pipeline...\")\n",
    "pipeline = TrainingPipeline(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    learning_rate=config['learning_rate'],\n",
    "    num_epochs=config['num_epochs'],\n",
    "    checkpoint_dir='checkpoints'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5A: Starting training...\n",
      "\n",
      "============================================================\n",
      "Epoch 1/20\n",
      "============================================================\n",
      "Epoch 0, Batch 0/21: Loss=1.9739, Contrastive=2.7776, Archetype=0.0990\n",
      "Epoch 0, Batch 10/21: Loss=1.9679, Contrastive=2.7758, Archetype=0.0866\n",
      "Epoch 0, Batch 20/21: Loss=1.8013, Contrastive=2.5328, Archetype=0.0963\n",
      "\n",
      "Train Losses: {'total': np.float64(1.9669640064239502), 'contrastive': np.float64(2.7668586117880687), 'archetype': np.float64(0.10301079423654647)}\n",
      "Val Losses: {'total': 1.8935595989227294, 'contrastive': 2.664562702178955, 'archetype': 0.09419761896133423}\n",
      "Checkpoint saved to checkpoints/fine_tune_A/best_model.pth\n",
      "✓ Best model saved (val_loss: 1.8936)\n",
      "\n",
      "============================================================\n",
      "Epoch 2/20\n",
      "============================================================\n",
      "Epoch 1, Batch 0/21: Loss=1.9037, Contrastive=2.6735, Archetype=0.1133\n",
      "Epoch 1, Batch 10/21: Loss=1.9206, Contrastive=2.6979, Archetype=0.1123\n",
      "Epoch 1, Batch 20/21: Loss=1.7890, Contrastive=2.5132, Archetype=0.1014\n",
      "\n",
      "Train Losses: {'total': np.float64(1.909187952677409), 'contrastive': np.float64(2.684551965622675), 'archetype': np.float64(0.10219607182911464)}\n",
      "Val Losses: {'total': 1.921950387954712, 'contrastive': 2.705440044403076, 'archetype': 0.09303464442491531}\n",
      "\n",
      "============================================================\n",
      "Epoch 3/20\n",
      "============================================================\n",
      "Epoch 2, Batch 0/21: Loss=1.9334, Contrastive=2.7139, Archetype=0.1152\n",
      "Epoch 2, Batch 10/21: Loss=1.8605, Contrastive=2.6244, Archetype=0.0820\n",
      "Epoch 2, Batch 20/21: Loss=1.5983, Contrastive=2.2456, Archetype=0.0858\n",
      "\n",
      "Train Losses: {'total': np.float64(1.8396917695090884), 'contrastive': np.float64(2.5857383069537936), 'archetype': np.float64(0.10056796031338829)}\n",
      "Val Losses: {'total': 1.9928571224212646, 'contrastive': 2.8074536323547363, 'archetype': 0.09049753695726395}\n",
      "\n",
      "============================================================\n",
      "Epoch 4/20\n",
      "============================================================\n",
      "Epoch 3, Batch 0/21: Loss=1.6633, Contrastive=2.3323, Archetype=0.1032\n",
      "Epoch 3, Batch 10/21: Loss=1.6850, Contrastive=2.3747, Archetype=0.0724\n",
      "Epoch 3, Batch 20/21: Loss=1.6359, Contrastive=2.2818, Archetype=0.1297\n",
      "\n",
      "Train Losses: {'total': np.float64(1.7586770682107835), 'contrastive': np.float64(2.4704699289231074), 'archetype': np.float64(0.09879274879183088)}\n",
      "Val Losses: {'total': 1.9221435070037842, 'contrastive': 2.7069230556488035, 'archetype': 0.08878571689128875}\n",
      "\n",
      "============================================================\n",
      "Epoch 5/20\n",
      "============================================================\n",
      "Epoch 4, Batch 0/21: Loss=1.7470, Contrastive=2.4668, Archetype=0.0694\n",
      "Epoch 4, Batch 10/21: Loss=1.6500, Contrastive=2.3090, Archetype=0.1116\n",
      "Epoch 4, Batch 20/21: Loss=1.6494, Contrastive=2.3153, Archetype=0.0948\n",
      "\n",
      "Train Losses: {'total': np.float64(1.7021401496160597), 'contrastive': np.float64(2.39022353717259), 'archetype': np.float64(0.09707401941219966)}\n",
      "Val Losses: {'total': 1.8732138872146606, 'contrastive': 2.63653244972229, 'archetype': 0.09050105214118957}\n",
      "Checkpoint saved to checkpoints/fine_tune_A/best_model.pth\n",
      "✓ Best model saved (val_loss: 1.8732)\n",
      "\n",
      "============================================================\n",
      "Epoch 6/20\n",
      "============================================================\n",
      "Epoch 5, Batch 0/21: Loss=1.7188, Contrastive=2.4119, Archetype=0.1019\n",
      "Epoch 5, Batch 10/21: Loss=1.7101, Contrastive=2.3939, Archetype=0.1177\n",
      "Epoch 5, Batch 20/21: Loss=1.4125, Contrastive=1.9696, Archetype=0.1142\n",
      "\n",
      "Train Losses: {'total': np.float64(1.6177064691271101), 'contrastive': np.float64(2.2697262934276035), 'archetype': np.float64(0.0965952007543473)}\n",
      "Val Losses: {'total': 1.86772940158844, 'contrastive': 2.6282982349395754, 'archetype': 0.09190106242895127}\n",
      "Checkpoint saved to checkpoints/fine_tune_A/best_model.pth\n",
      "✓ Best model saved (val_loss: 1.8677)\n",
      "\n",
      "============================================================\n",
      "Epoch 7/20\n",
      "============================================================\n",
      "Epoch 6, Batch 0/21: Loss=1.4725, Contrastive=2.0635, Archetype=0.0955\n",
      "Epoch 6, Batch 10/21: Loss=1.6880, Contrastive=2.3813, Archetype=0.0669\n",
      "Epoch 6, Batch 20/21: Loss=1.5264, Contrastive=2.1335, Archetype=0.1137\n",
      "\n",
      "Train Losses: {'total': np.float64(1.577610867364066), 'contrastive': np.float64(2.2129634278161183), 'archetype': np.float64(0.0948500374243373)}\n",
      "Val Losses: {'total': 1.9064867496490479, 'contrastive': 2.685256099700928, 'archetype': 0.0863403096795082}\n",
      "\n",
      "============================================================\n",
      "Epoch 8/20\n",
      "============================================================\n",
      "Epoch 7, Batch 0/21: Loss=1.6757, Contrastive=2.3506, Archetype=0.1006\n",
      "Epoch 7, Batch 10/21: Loss=1.4308, Contrastive=2.0016, Archetype=0.0944\n",
      "Epoch 7, Batch 20/21: Loss=1.3145, Contrastive=1.8277, Archetype=0.1200\n",
      "\n",
      "Train Losses: {'total': np.float64(1.5475531419118245), 'contrastive': np.float64(2.1699151481900896), 'archetype': np.float64(0.09518810060052645)}\n",
      "Val Losses: {'total': 1.8966990947723388, 'contrastive': 2.669869804382324, 'archetype': 0.09124891608953475}\n",
      "\n",
      "============================================================\n",
      "Epoch 9/20\n",
      "============================================================\n",
      "Epoch 8, Batch 0/21: Loss=1.4800, Contrastive=2.0708, Archetype=0.0987\n",
      "Epoch 8, Batch 10/21: Loss=1.4191, Contrastive=2.0012, Archetype=0.0619\n",
      "Epoch 8, Batch 20/21: Loss=1.2908, Contrastive=1.7911, Archetype=0.1268\n",
      "\n",
      "Train Losses: {'total': np.float64(1.4701202426637923), 'contrastive': np.float64(2.0608069556100026), 'archetype': np.float64(0.089853423869326)}\n",
      "Val Losses: {'total': 1.852534580230713, 'contrastive': 2.6078625679016114, 'archetype': 0.08744957149028779}\n",
      "Checkpoint saved to checkpoints/fine_tune_A/best_model.pth\n",
      "✓ Best model saved (val_loss: 1.8525)\n",
      "\n",
      "============================================================\n",
      "Epoch 10/20\n",
      "============================================================\n",
      "Epoch 9, Batch 0/21: Loss=1.4465, Contrastive=2.0240, Archetype=0.0954\n",
      "Epoch 9, Batch 10/21: Loss=1.5329, Contrastive=2.1469, Archetype=0.0979\n",
      "Epoch 9, Batch 20/21: Loss=1.3182, Contrastive=1.8500, Archetype=0.0764\n",
      "\n",
      "Train Losses: {'total': np.float64(1.4227968738192605), 'contrastive': np.float64(1.9923359325953893), 'archetype': np.float64(0.09304455011373475)}\n",
      "Val Losses: {'total': 1.870309829711914, 'contrastive': 2.632224178314209, 'archetype': 0.09106273651123047}\n",
      "Checkpoint saved to checkpoints/fine_tune_A/checkpoint_epoch_10.pth\n",
      "\n",
      "============================================================\n",
      "Epoch 11/20\n",
      "============================================================\n",
      "Epoch 10, Batch 0/21: Loss=1.3373, Contrastive=1.8730, Archetype=0.0820\n",
      "Epoch 10, Batch 10/21: Loss=1.4998, Contrastive=2.1084, Archetype=0.0786\n",
      "Epoch 10, Batch 20/21: Loss=1.2577, Contrastive=1.7577, Archetype=0.0929\n",
      "\n",
      "Train Losses: {'total': np.float64(1.3995962824140276), 'contrastive': np.float64(1.9597242389406477), 'archetype': np.float64(0.09117353246325538)}\n",
      "Val Losses: {'total': 1.9036454439163208, 'contrastive': 2.6810813903808595, 'archetype': 0.0867379993200302}\n",
      "\n",
      "============================================================\n",
      "Epoch 12/20\n",
      "============================================================\n",
      "Epoch 11, Batch 0/21: Loss=1.2859, Contrastive=1.7987, Archetype=0.0906\n",
      "Epoch 11, Batch 10/21: Loss=1.3283, Contrastive=1.8562, Archetype=0.0967\n",
      "Epoch 11, Batch 20/21: Loss=1.2341, Contrastive=1.7287, Archetype=0.0827\n",
      "\n",
      "Train Losses: {'total': np.float64(1.350777995018732), 'contrastive': np.float64(1.8893472183318365), 'archetype': np.float64(0.09344400181656792)}\n",
      "Val Losses: {'total': 1.9016775131225585, 'contrastive': 2.677446222305298, 'archetype': 0.08962105065584183}\n",
      "\n",
      "============================================================\n",
      "Epoch 13/20\n",
      "============================================================\n",
      "Epoch 12, Batch 0/21: Loss=1.2959, Contrastive=1.8108, Archetype=0.0875\n",
      "Epoch 12, Batch 10/21: Loss=1.1664, Contrastive=1.6176, Archetype=0.1100\n",
      "Epoch 12, Batch 20/21: Loss=1.1601, Contrastive=1.6208, Archetype=0.0817\n",
      "\n",
      "Train Losses: {'total': np.float64(1.3152842805499123), 'contrastive': np.float64(1.838982758067903), 'archetype': np.float64(0.09216050519829705)}\n",
      "Val Losses: {'total': 1.885330891609192, 'contrastive': 2.6538368225097657, 'archetype': 0.09052467346191406}\n",
      "\n",
      "============================================================\n",
      "Epoch 14/20\n",
      "============================================================\n",
      "Epoch 13, Batch 0/21: Loss=1.2385, Contrastive=1.7376, Archetype=0.0739\n",
      "Epoch 13, Batch 10/21: Loss=1.1645, Contrastive=1.6224, Archetype=0.0983\n",
      "Epoch 13, Batch 20/21: Loss=1.1624, Contrastive=1.6315, Archetype=0.0630\n",
      "\n",
      "Train Losses: {'total': np.float64(1.2552180801119124), 'contrastive': np.float64(1.7534829151062739), 'archetype': np.float64(0.09114878447282881)}\n",
      "Val Losses: {'total': 1.9259876489639283, 'contrastive': 2.7121763706207274, 'archetype': 0.08961831331253052}\n",
      "\n",
      "============================================================\n",
      "Epoch 15/20\n",
      "============================================================\n",
      "Epoch 14, Batch 0/21: Loss=1.3159, Contrastive=1.8414, Archetype=0.0909\n",
      "Epoch 14, Batch 10/21: Loss=1.3503, Contrastive=1.8953, Archetype=0.0745\n",
      "Epoch 14, Batch 20/21: Loss=1.0125, Contrastive=1.4086, Archetype=0.0825\n",
      "\n",
      "Train Losses: {'total': np.float64(1.271953821182251), 'contrastive': np.float64(1.7771416789009458), 'archetype': np.float64(0.09195467315259434)}\n",
      "Val Losses: {'total': 1.9576950788497924, 'contrastive': 2.758227300643921, 'archetype': 0.08697338700294495}\n",
      "\n",
      "============================================================\n",
      "Epoch 16/20\n",
      "============================================================\n",
      "Epoch 15, Batch 0/21: Loss=1.1503, Contrastive=1.6035, Archetype=0.0918\n",
      "Epoch 15, Batch 10/21: Loss=1.2212, Contrastive=1.6944, Archetype=0.1165\n",
      "Epoch 15, Batch 20/21: Loss=1.0558, Contrastive=1.4666, Archetype=0.1009\n",
      "\n",
      "Train Losses: {'total': np.float64(1.2063019559496926), 'contrastive': np.float64(1.6837319703329177), 'archetype': np.float64(0.09065870851987884)}\n",
      "Val Losses: {'total': 1.9056671619415284, 'contrastive': 2.682952880859375, 'archetype': 0.09030172675848007}\n",
      "\n",
      "============================================================\n",
      "Epoch 17/20\n",
      "============================================================\n",
      "Epoch 16, Batch 0/21: Loss=1.1482, Contrastive=1.6014, Archetype=0.0872\n",
      "Epoch 16, Batch 10/21: Loss=1.2121, Contrastive=1.6891, Archetype=0.0985\n",
      "Epoch 16, Batch 20/21: Loss=0.9109, Contrastive=1.2586, Archetype=0.0967\n",
      "\n",
      "Train Losses: {'total': np.float64(1.16959928330921), 'contrastive': np.float64(1.6309955290385656), 'archetype': np.float64(0.09166049088040988)}\n",
      "Val Losses: {'total': 1.983335518836975, 'contrastive': 2.7945559501647947, 'archetype': 0.08803545534610749}\n",
      "\n",
      "============================================================\n",
      "Epoch 18/20\n",
      "============================================================\n",
      "Epoch 17, Batch 0/21: Loss=1.1159, Contrastive=1.5530, Archetype=0.0947\n",
      "Epoch 17, Batch 10/21: Loss=1.1759, Contrastive=1.6440, Archetype=0.0832\n",
      "Epoch 17, Batch 20/21: Loss=0.9722, Contrastive=1.3482, Archetype=0.0931\n",
      "\n",
      "Train Losses: {'total': np.float64(1.1584677696228027), 'contrastive': np.float64(1.614206490062532), 'archetype': np.float64(0.0947854533081963)}\n",
      "Val Losses: {'total': 1.9401558876037597, 'contrastive': 2.732040357589722, 'archetype': 0.09093583673238755}\n",
      "\n",
      "============================================================\n",
      "Epoch 19/20\n",
      "============================================================\n",
      "Epoch 18, Batch 0/21: Loss=1.0938, Contrastive=1.5281, Archetype=0.0781\n",
      "Epoch 18, Batch 10/21: Loss=1.0004, Contrastive=1.3839, Archetype=0.1031\n",
      "Epoch 18, Batch 20/21: Loss=0.9597, Contrastive=1.3319, Archetype=0.0902\n",
      "\n",
      "Train Losses: {'total': np.float64(1.1465639074643452), 'contrastive': np.float64(1.5980693669546218), 'archetype': np.float64(0.09175620600581169)}\n",
      "Val Losses: {'total': 1.9655653238296509, 'contrastive': 2.7692017555236816, 'archetype': 0.08791563808917999}\n",
      "\n",
      "============================================================\n",
      "Epoch 20/20\n",
      "============================================================\n",
      "Epoch 19, Batch 0/21: Loss=0.9983, Contrastive=1.3911, Archetype=0.0796\n",
      "Epoch 19, Batch 10/21: Loss=1.2438, Contrastive=1.7369, Archetype=0.0961\n",
      "Epoch 19, Batch 20/21: Loss=0.9339, Contrastive=1.2916, Archetype=0.1005\n",
      "\n",
      "Train Losses: {'total': np.float64(1.0937892936524891), 'contrastive': np.float64(1.5218074037915184), 'archetype': np.float64(0.09479235769027755)}\n",
      "Val Losses: {'total': 1.9383788585662842, 'contrastive': 2.729096841812134, 'archetype': 0.09235343039035797}\n",
      "Checkpoint saved to checkpoints/fine_tune_A/checkpoint_epoch_20.pth\n",
      "\n",
      "============================================================\n",
      "Training complete!\n",
      "============================================================\n",
      "Checkpoint saved to checkpoints/fine_tune_A/final_model.pth\n",
      "Training history plot saved to checkpoints/fine_tune_A/training_history.png\n",
      "\n",
      "✓ Training complete! Model checkpoints saved to checkpoints/fine_tune_A\n"
     ]
    }
   ],
   "source": [
    "# Step 5A: Train!Fine-tuning  Approach A (Projection-only) ONLY\n",
    "\n",
    "print(\"\\nStep 5A: Starting training...\")\n",
    "pipeline.checkpoint_dir = Path(\"checkpoints/fine_tune_A\")\n",
    "pipeline.checkpoint_dir.mkdir(exist_ok=True, parents=True)\n",
    "pipeline.train()\n",
    "\n",
    "print(\"\\n✓ Training complete! Model checkpoints saved to checkpoints/fine_tune_A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5B: Starting training...\n",
      "\n",
      "============================================================\n",
      "Epoch 1/20\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zain/anaconda3/envs/lab3py313/lib/python3.13/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0/42: Loss=1.9790, Contrastive=2.7697, Archetype=0.1402\n",
      "Epoch 0, Batch 10/42: Loss=1.9659, Contrastive=2.7584, Archetype=0.1212\n",
      "Epoch 0, Batch 20/42: Loss=1.9612, Contrastive=2.7516, Archetype=0.1155\n",
      "Epoch 0, Batch 30/42: Loss=1.9381, Contrastive=2.7245, Archetype=0.1051\n",
      "Epoch 0, Batch 40/42: Loss=1.8933, Contrastive=2.6678, Archetype=0.0879\n",
      "\n",
      "Train Losses: {'total': np.float64(1.966353450502668), 'contrastive': np.float64(2.7659767866134644), 'archetype': np.float64(0.10304137957947594)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zain/anaconda3/envs/lab3py313/lib/python3.13/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Losses: {'total': 1.9410083956188626, 'contrastive': 2.733148733774821, 'archetype': 0.09454374180899726}\n",
      "Checkpoint saved to checkpoints/fine_tune_B/best_model.pth\n",
      "✓ Best model saved (val_loss: 1.9410)\n",
      "\n",
      "============================================================\n",
      "Epoch 2/20\n",
      "============================================================\n",
      "Epoch 1, Batch 0/42: Loss=1.9640, Contrastive=2.7560, Archetype=0.1205\n",
      "Epoch 1, Batch 10/42: Loss=1.9676, Contrastive=2.7663, Archetype=0.1109\n",
      "Epoch 1, Batch 20/42: Loss=1.9164, Contrastive=2.6975, Archetype=0.0910\n",
      "Epoch 1, Batch 30/42: Loss=1.9224, Contrastive=2.7106, Archetype=0.0855\n",
      "Epoch 1, Batch 40/42: Loss=1.7932, Contrastive=2.5238, Archetype=0.0928\n",
      "\n",
      "Train Losses: {'total': np.float64(1.906069034621829), 'contrastive': np.float64(2.679955925260271), 'archetype': np.float64(0.1027061307714099)}\n",
      "Val Losses: {'total': 1.9074376026789348, 'contrastive': 2.687011374367608, 'archetype': 0.0881727925605244}\n",
      "Checkpoint saved to checkpoints/fine_tune_B/best_model.pth\n",
      "✓ Best model saved (val_loss: 1.9074)\n",
      "\n",
      "============================================================\n",
      "Epoch 3/20\n",
      "============================================================\n",
      "Epoch 2, Batch 0/42: Loss=1.9083, Contrastive=2.6791, Archetype=0.1133\n",
      "Epoch 2, Batch 10/42: Loss=1.8789, Contrastive=2.6453, Archetype=0.0920\n",
      "Epoch 2, Batch 20/42: Loss=1.8371, Contrastive=2.5742, Archetype=0.1229\n",
      "Epoch 2, Batch 30/42: Loss=1.8146, Contrastive=2.5491, Archetype=0.1036\n",
      "Epoch 2, Batch 40/42: Loss=1.7840, Contrastive=2.5079, Archetype=0.0978\n",
      "\n",
      "Train Losses: {'total': np.float64(1.821306484086173), 'contrastive': np.float64(2.5593833525975547), 'archetype': np.float64(0.10080691001244954)}\n",
      "Val Losses: {'total': 1.896610312991672, 'contrastive': 2.671480311287774, 'archetype': 0.08839603430695003}\n",
      "Checkpoint saved to checkpoints/fine_tune_B/best_model.pth\n",
      "✓ Best model saved (val_loss: 1.8966)\n",
      "\n",
      "============================================================\n",
      "Epoch 4/20\n",
      "============================================================\n",
      "Epoch 3, Batch 0/42: Loss=1.8017, Contrastive=2.5237, Archetype=0.1174\n",
      "Epoch 3, Batch 10/42: Loss=1.8550, Contrastive=2.6010, Archetype=0.1151\n",
      "Epoch 3, Batch 20/42: Loss=1.7463, Contrastive=2.4605, Archetype=0.0809\n",
      "Epoch 3, Batch 30/42: Loss=1.8151, Contrastive=2.5443, Archetype=0.1165\n",
      "Epoch 3, Batch 40/42: Loss=1.7856, Contrastive=2.5163, Archetype=0.0794\n",
      "\n",
      "Train Losses: {'total': np.float64(1.7621684216317677), 'contrastive': np.float64(2.475323892775036), 'archetype': np.float64(0.099336799500244)}\n",
      "Val Losses: {'total': 1.8871117168002658, 'contrastive': 2.658557997809516, 'archetype': 0.0861302903956837}\n",
      "Checkpoint saved to checkpoints/fine_tune_B/best_model.pth\n",
      "✓ Best model saved (val_loss: 1.8871)\n",
      "\n",
      "============================================================\n",
      "Epoch 5/20\n",
      "============================================================\n",
      "Epoch 4, Batch 0/42: Loss=1.6588, Contrastive=2.3259, Archetype=0.1027\n",
      "Epoch 4, Batch 10/42: Loss=1.6961, Contrastive=2.3797, Archetype=0.0966\n",
      "Epoch 4, Batch 20/42: Loss=1.5862, Contrastive=2.2276, Archetype=0.0908\n",
      "Epoch 4, Batch 30/42: Loss=1.6142, Contrastive=2.2604, Archetype=0.1114\n",
      "Epoch 4, Batch 40/42: Loss=1.7197, Contrastive=2.4086, Archetype=0.1123\n",
      "\n",
      "Train Losses: {'total': np.float64(1.7009733205749875), 'contrastive': np.float64(2.387567633674258), 'archetype': np.float64(0.10050549801616442)}\n",
      "Val Losses: {'total': 1.8699662817849054, 'contrastive': 2.633251508076986, 'archetype': 0.08897430366939968}\n",
      "Checkpoint saved to checkpoints/fine_tune_B/best_model.pth\n",
      "✓ Best model saved (val_loss: 1.8700)\n",
      "\n",
      "============================================================\n",
      "Epoch 6/20\n",
      "============================================================\n",
      "Epoch 5, Batch 0/42: Loss=1.5913, Contrastive=2.2308, Archetype=0.0997\n",
      "Epoch 5, Batch 10/42: Loss=1.6109, Contrastive=2.2647, Archetype=0.0820\n",
      "Epoch 5, Batch 20/42: Loss=1.5721, Contrastive=2.2012, Archetype=0.1046\n",
      "Epoch 5, Batch 30/42: Loss=1.6164, Contrastive=2.2809, Archetype=0.0658\n",
      "Epoch 5, Batch 40/42: Loss=1.6119, Contrastive=2.2692, Archetype=0.0797\n",
      "\n",
      "Train Losses: {'total': np.float64(1.6551370876176017), 'contrastive': np.float64(2.3220391614096507), 'archetype': np.float64(0.10063508330356508)}\n",
      "Val Losses: {'total': 1.8633826573689778, 'contrastive': 2.623493644926283, 'archetype': 0.09021074987120098}\n",
      "Checkpoint saved to checkpoints/fine_tune_B/best_model.pth\n",
      "✓ Best model saved (val_loss: 1.8634)\n",
      "\n",
      "============================================================\n",
      "Epoch 7/20\n",
      "============================================================\n",
      "Epoch 6, Batch 0/42: Loss=1.6715, Contrastive=2.3428, Archetype=0.0988\n",
      "Epoch 6, Batch 10/42: Loss=1.5904, Contrastive=2.2326, Archetype=0.0943\n",
      "Epoch 6, Batch 20/42: Loss=1.5364, Contrastive=2.1612, Archetype=0.0818\n",
      "Epoch 6, Batch 30/42: Loss=1.7351, Contrastive=2.4349, Archetype=0.1041\n",
      "Epoch 6, Batch 40/42: Loss=1.7053, Contrastive=2.3904, Archetype=0.1074\n",
      "\n",
      "Train Losses: {'total': np.float64(1.6158552936145238), 'contrastive': np.float64(2.2661438697860357), 'archetype': np.float64(0.09989053152856373)}\n",
      "Val Losses: {'total': 1.85145099957784, 'contrastive': 2.6068290074666343, 'archetype': 0.08887720025247997}\n",
      "Checkpoint saved to checkpoints/fine_tune_B/best_model.pth\n",
      "✓ Best model saved (val_loss: 1.8515)\n",
      "\n",
      "============================================================\n",
      "Epoch 8/20\n",
      "============================================================\n",
      "Epoch 7, Batch 0/42: Loss=1.5577, Contrastive=2.1813, Archetype=0.1061\n",
      "Epoch 7, Batch 10/42: Loss=1.6453, Contrastive=2.2857, Archetype=0.1588\n",
      "Epoch 7, Batch 20/42: Loss=1.5610, Contrastive=2.1736, Archetype=0.1382\n",
      "Epoch 7, Batch 30/42: Loss=1.5310, Contrastive=2.1549, Archetype=0.0748\n",
      "Epoch 7, Batch 40/42: Loss=1.5645, Contrastive=2.2013, Archetype=0.0784\n",
      "\n",
      "Train Losses: {'total': np.float64(1.5665181818462552), 'contrastive': np.float64(2.195354495729719), 'archetype': np.float64(0.10095216378214814)}\n",
      "Val Losses: {'total': 1.857993245124817, 'contrastive': 2.6167160669962564, 'archetype': 0.08698480410708322}\n",
      "\n",
      "============================================================\n",
      "Epoch 9/20\n",
      "============================================================\n",
      "Epoch 8, Batch 0/42: Loss=1.5774, Contrastive=2.2166, Archetype=0.0902\n",
      "Epoch 8, Batch 10/42: Loss=1.4530, Contrastive=2.0329, Archetype=0.1001\n",
      "Epoch 8, Batch 20/42: Loss=1.4459, Contrastive=2.0234, Archetype=0.0999\n",
      "Epoch 8, Batch 30/42: Loss=1.5228, Contrastive=2.1357, Archetype=0.0938\n",
      "Epoch 8, Batch 40/42: Loss=1.5442, Contrastive=2.1614, Archetype=0.1017\n",
      "\n",
      "Train Losses: {'total': np.float64(1.5429030997412545), 'contrastive': np.float64(2.1623028885750544), 'archetype': np.float64(0.098576239886738)}\n",
      "Val Losses: {'total': 1.891992039150662, 'contrastive': 2.6655232111612954, 'archetype': 0.08615572171078788}\n",
      "\n",
      "============================================================\n",
      "Epoch 10/20\n",
      "============================================================\n",
      "Epoch 9, Batch 0/42: Loss=1.4936, Contrastive=2.0840, Archetype=0.1212\n",
      "Epoch 9, Batch 10/42: Loss=1.4468, Contrastive=2.0329, Archetype=0.0802\n",
      "Epoch 9, Batch 20/42: Loss=1.4960, Contrastive=2.0899, Archetype=0.1129\n",
      "Epoch 9, Batch 30/42: Loss=1.4272, Contrastive=1.9926, Archetype=0.1092\n",
      "Epoch 9, Batch 40/42: Loss=1.4461, Contrastive=2.0117, Archetype=0.1305\n",
      "\n",
      "Train Losses: {'total': np.float64(1.5064858198165894), 'contrastive': np.float64(2.1106452572913397), 'archetype': np.float64(0.09736704578002293)}\n",
      "Val Losses: {'total': 1.8903788725535076, 'contrastive': 2.6629212697347007, 'archetype': 0.08719578054216173}\n",
      "Checkpoint saved to checkpoints/fine_tune_B/checkpoint_epoch_10.pth\n",
      "\n",
      "============================================================\n",
      "Epoch 11/20\n",
      "============================================================\n",
      "Epoch 10, Batch 0/42: Loss=1.4969, Contrastive=2.0998, Archetype=0.0950\n",
      "Epoch 10, Batch 10/42: Loss=1.4905, Contrastive=2.0817, Archetype=0.1100\n",
      "Epoch 10, Batch 20/42: Loss=1.4446, Contrastive=2.0242, Archetype=0.0913\n",
      "Epoch 10, Batch 30/42: Loss=1.3767, Contrastive=1.9384, Archetype=0.0658\n",
      "Epoch 10, Batch 40/42: Loss=1.4290, Contrastive=2.0010, Archetype=0.0896\n",
      "\n",
      "Train Losses: {'total': np.float64(1.4714838096073695), 'contrastive': np.float64(2.0607125844274248), 'archetype': np.float64(0.09708736384553569)}\n",
      "Val Losses: {'total': 1.8696402708689372, 'contrastive': 2.633792426851061, 'archetype': 0.08545307483938006}\n",
      "\n",
      "============================================================\n",
      "Epoch 12/20\n",
      "============================================================\n",
      "Epoch 11, Batch 0/42: Loss=1.4088, Contrastive=1.9722, Archetype=0.0937\n",
      "Epoch 11, Batch 10/42: Loss=1.5235, Contrastive=2.1385, Archetype=0.0892\n",
      "Epoch 11, Batch 20/42: Loss=1.4712, Contrastive=2.0638, Archetype=0.0917\n",
      "Epoch 11, Batch 30/42: Loss=1.5278, Contrastive=2.1406, Archetype=0.1007\n",
      "Epoch 11, Batch 40/42: Loss=1.4563, Contrastive=2.0339, Archetype=0.1090\n",
      "\n",
      "Train Losses: {'total': np.float64(1.4619736728214083), 'contrastive': np.float64(2.0473823149998984), 'archetype': np.float64(0.0961312356271914)}\n",
      "Val Losses: {'total': 1.8748953474892511, 'contrastive': 2.640679571363661, 'archetype': 0.08762291487720278}\n",
      "\n",
      "============================================================\n",
      "Epoch 13/20\n",
      "============================================================\n",
      "Epoch 12, Batch 0/42: Loss=1.4696, Contrastive=2.0448, Archetype=0.1264\n",
      "Epoch 12, Batch 10/42: Loss=1.4311, Contrastive=2.0177, Archetype=0.0635\n",
      "Epoch 12, Batch 20/42: Loss=1.6307, Contrastive=2.2781, Archetype=0.1197\n",
      "Epoch 12, Batch 30/42: Loss=1.3872, Contrastive=1.9253, Archetype=0.1283\n",
      "Epoch 12, Batch 40/42: Loss=1.5261, Contrastive=2.1315, Archetype=0.1178\n",
      "\n",
      "Train Losses: {'total': np.float64(1.4576149100349063), 'contrastive': np.float64(2.0411464231354848), 'archetype': np.float64(0.09627243308793931)}\n",
      "Val Losses: {'total': 1.869409163792928, 'contrastive': 2.6326747470431857, 'archetype': 0.08820895685089959}\n",
      "\n",
      "============================================================\n",
      "Epoch 14/20\n",
      "============================================================\n",
      "Epoch 13, Batch 0/42: Loss=1.4242, Contrastive=1.9965, Archetype=0.0883\n",
      "Epoch 13, Batch 10/42: Loss=1.5382, Contrastive=2.1518, Archetype=0.1078\n",
      "Epoch 13, Batch 20/42: Loss=1.3853, Contrastive=1.9410, Archetype=0.0885\n",
      "Epoch 13, Batch 30/42: Loss=1.4113, Contrastive=1.9763, Archetype=0.0948\n",
      "Epoch 13, Batch 40/42: Loss=1.4161, Contrastive=1.9807, Archetype=0.1024\n",
      "\n",
      "Train Losses: {'total': np.float64(1.4082142171405612), 'contrastive': np.float64(1.9702108757836478), 'archetype': np.float64(0.09750341428887277)}\n",
      "Val Losses: {'total': 1.8614463541242812, 'contrastive': 2.621918890211317, 'archetype': 0.08604137599468231}\n",
      "\n",
      "============================================================\n",
      "Epoch 15/20\n",
      "============================================================\n",
      "Epoch 14, Batch 0/42: Loss=1.3724, Contrastive=1.9244, Archetype=0.0837\n",
      "Epoch 14, Batch 10/42: Loss=1.4316, Contrastive=2.0035, Archetype=0.1058\n",
      "Epoch 14, Batch 20/42: Loss=1.3564, Contrastive=1.8962, Archetype=0.0919\n",
      "Epoch 14, Batch 30/42: Loss=1.3240, Contrastive=1.8520, Archetype=0.0939\n",
      "Epoch 14, Batch 40/42: Loss=1.4446, Contrastive=2.0144, Archetype=0.1183\n",
      "\n",
      "Train Losses: {'total': np.float64(1.388782418909527), 'contrastive': np.float64(1.9423932631810505), 'archetype': np.float64(0.09765311694216161)}\n",
      "Val Losses: {'total': 1.8701328304078844, 'contrastive': 2.633785274293688, 'archetype': 0.08793992549180984}\n",
      "\n",
      "============================================================\n",
      "Epoch 16/20\n",
      "============================================================\n",
      "Epoch 15, Batch 0/42: Loss=1.3207, Contrastive=1.8378, Archetype=0.1110\n",
      "Epoch 15, Batch 10/42: Loss=1.5118, Contrastive=2.1209, Archetype=0.0850\n",
      "Epoch 15, Batch 20/42: Loss=1.3847, Contrastive=1.9393, Archetype=0.0946\n",
      "Epoch 15, Batch 30/42: Loss=1.4589, Contrastive=2.0376, Archetype=0.1037\n",
      "Epoch 15, Batch 40/42: Loss=1.2992, Contrastive=1.8221, Archetype=0.0788\n",
      "\n",
      "Train Losses: {'total': np.float64(1.3539932824316478), 'contrastive': np.float64(1.8929850515865145), 'archetype': np.float64(0.09663561075216248)}\n",
      "Val Losses: {'total': 1.846811956829495, 'contrastive': 2.600960281160143, 'archetype': 0.08622170570823881}\n",
      "Checkpoint saved to checkpoints/fine_tune_B/best_model.pth\n",
      "✓ Best model saved (val_loss: 1.8468)\n",
      "\n",
      "============================================================\n",
      "Epoch 17/20\n",
      "============================================================\n",
      "Epoch 16, Batch 0/42: Loss=1.4424, Contrastive=2.0125, Archetype=0.1105\n",
      "Epoch 16, Batch 10/42: Loss=1.4439, Contrastive=2.0215, Archetype=0.0937\n",
      "Epoch 16, Batch 20/42: Loss=1.2687, Contrastive=1.7664, Archetype=0.1060\n",
      "Epoch 16, Batch 30/42: Loss=1.2367, Contrastive=1.7264, Archetype=0.0938\n",
      "Epoch 16, Batch 40/42: Loss=1.3808, Contrastive=1.9300, Archetype=0.1009\n",
      "\n",
      "Train Losses: {'total': np.float64(1.3595212187085832), 'contrastive': np.float64(1.9016804127466111), 'archetype': np.float64(0.09393389008584477)}\n",
      "Val Losses: {'total': 1.8631664249632094, 'contrastive': 2.6232788032955594, 'archetype': 0.08988093998697069}\n",
      "\n",
      "============================================================\n",
      "Epoch 18/20\n",
      "============================================================\n",
      "Epoch 17, Batch 0/42: Loss=1.5365, Contrastive=2.1573, Archetype=0.0876\n",
      "Epoch 17, Batch 10/42: Loss=1.3345, Contrastive=1.8640, Archetype=0.1002\n",
      "Epoch 17, Batch 20/42: Loss=1.3067, Contrastive=1.8290, Archetype=0.0861\n",
      "Epoch 17, Batch 30/42: Loss=1.4184, Contrastive=1.9807, Archetype=0.1063\n",
      "Epoch 17, Batch 40/42: Loss=1.3518, Contrastive=1.8874, Archetype=0.1015\n",
      "\n",
      "Train Losses: {'total': np.float64(1.3344132417724246), 'contrastive': np.float64(1.8650073579379491), 'archetype': np.float64(0.09671072626397723)}\n",
      "Val Losses: {'total': 1.887357817755805, 'contrastive': 2.658661815855238, 'archetype': 0.08699706279569203}\n",
      "\n",
      "============================================================\n",
      "Epoch 19/20\n",
      "============================================================\n",
      "Epoch 18, Batch 0/42: Loss=1.2473, Contrastive=1.7378, Archetype=0.1063\n",
      "Epoch 18, Batch 10/42: Loss=1.2947, Contrastive=1.8022, Archetype=0.1118\n",
      "Epoch 18, Batch 20/42: Loss=1.2467, Contrastive=1.7433, Archetype=0.0891\n",
      "Epoch 18, Batch 30/42: Loss=1.4467, Contrastive=2.0188, Archetype=0.1077\n",
      "Epoch 18, Batch 40/42: Loss=1.4418, Contrastive=2.0237, Archetype=0.0844\n",
      "\n",
      "Train Losses: {'total': np.float64(1.3152641143117632), 'contrastive': np.float64(1.838122234458015), 'archetype': np.float64(0.09502858624217056)}\n",
      "Val Losses: {'total': 1.8880462514029608, 'contrastive': 2.6593487527635364, 'archetype': 0.08803617374764548}\n",
      "\n",
      "============================================================\n",
      "Epoch 20/20\n",
      "============================================================\n",
      "Epoch 19, Batch 0/42: Loss=1.3030, Contrastive=1.8262, Archetype=0.0851\n",
      "Epoch 19, Batch 10/42: Loss=1.2995, Contrastive=1.8066, Archetype=0.1105\n",
      "Epoch 19, Batch 20/42: Loss=1.2509, Contrastive=1.7563, Archetype=0.0683\n",
      "Epoch 19, Batch 30/42: Loss=1.4215, Contrastive=1.9913, Archetype=0.0911\n",
      "Epoch 19, Batch 40/42: Loss=1.2513, Contrastive=1.7360, Archetype=0.1199\n",
      "\n",
      "Train Losses: {'total': np.float64(1.2988822289875575), 'contrastive': np.float64(1.8142274532999312), 'archetype': np.float64(0.09675106672304017)}\n",
      "Val Losses: {'total': 1.8806893693076239, 'contrastive': 2.6487792597876654, 'archetype': 0.08824565675523546}\n",
      "Checkpoint saved to checkpoints/fine_tune_B/checkpoint_epoch_20.pth\n",
      "\n",
      "============================================================\n",
      "Training complete!\n",
      "============================================================\n",
      "Checkpoint saved to checkpoints/fine_tune_B/final_model.pth\n",
      "Training history plot saved to checkpoints/fine_tune_B/training_history.png\n",
      "\n",
      "✓ Training complete! Model checkpoints saved to checkpoints/fine_tune_B\n"
     ]
    }
   ],
   "source": [
    "# Step 5B: Train!Fine-tuning  Approach A (Projection-only) ONLY\n",
    "\n",
    "print(\"\\nStep 5B: Starting training...\")\n",
    "pipeline.checkpoint_dir = Path(\"checkpoints/fine_tune_B\")\n",
    "pipeline.checkpoint_dir.mkdir(exist_ok=True, parents=True)\n",
    "pipeline.train()\n",
    "\n",
    "print(\"\\n✓ Training complete! Model checkpoints saved to checkpoints/fine_tune_B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5: Starting training...\n",
      "\n",
      "============================================================\n",
      "Epoch 1/20\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zain/anaconda3/envs/lab3py313/lib/python3.13/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0/21: Loss=1.9772, Contrastive=2.7725, Archetype=0.1295\n",
      "Epoch 0, Batch 10/21: Loss=1.9883, Contrastive=2.7958, Archetype=0.1115\n",
      "Epoch 0, Batch 20/21: Loss=1.7641, Contrastive=2.4914, Archetype=0.0669\n",
      "\n",
      "Train Losses: {'total': np.float64(1.9617775565101987), 'contrastive': np.float64(2.7585508823394775), 'archetype': np.float64(0.10732915713673546)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zain/anaconda3/envs/lab3py313/lib/python3.13/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Losses: {'total': 1.8791366338729858, 'contrastive': 2.6434515714645386, 'archetype': 0.09720117449760438}\n",
      "Checkpoint saved to checkpoints/best_model.pth\n",
      "✓ Best model saved (val_loss: 1.8791)\n",
      "\n",
      "============================================================\n",
      "Epoch 2/20\n",
      "============================================================\n",
      "Epoch 1, Batch 0/21: Loss=1.8743, Contrastive=2.6430, Archetype=0.0831\n",
      "Epoch 1, Batch 10/21: Loss=1.8963, Contrastive=2.6557, Archetype=0.1267\n",
      "Epoch 1, Batch 20/21: Loss=1.5718, Contrastive=2.2092, Archetype=0.0885\n",
      "\n",
      "Train Losses: {'total': np.float64(1.8077486412865775), 'contrastive': np.float64(2.5401792299179804), 'archetype': np.float64(0.10258456213133675)}\n",
      "Val Losses: {'total': 1.8059094190597533, 'contrastive': 2.5391037940979, 'archetype': 0.09716752469539643}\n",
      "Checkpoint saved to checkpoints/best_model.pth\n",
      "✓ Best model saved (val_loss: 1.8059)\n",
      "\n",
      "============================================================\n",
      "Epoch 3/20\n",
      "============================================================\n",
      "Epoch 2, Batch 0/21: Loss=1.6950, Contrastive=2.3698, Archetype=0.1257\n",
      "Epoch 2, Batch 10/21: Loss=1.6389, Contrastive=2.3039, Archetype=0.0885\n",
      "Epoch 2, Batch 20/21: Loss=1.3446, Contrastive=1.8780, Archetype=0.1042\n",
      "\n",
      "Train Losses: {'total': np.float64(1.5560827141716367), 'contrastive': np.float64(2.1814837001618885), 'archetype': np.float64(0.10010537859939393)}\n",
      "Val Losses: {'total': 1.8817809343338012, 'contrastive': 2.6483145713806153, 'archetype': 0.09422759860754013}\n",
      "\n",
      "============================================================\n",
      "Epoch 4/20\n",
      "============================================================\n",
      "Epoch 3, Batch 0/21: Loss=1.2273, Contrastive=1.7069, Archetype=0.1078\n",
      "Epoch 3, Batch 10/21: Loss=0.9349, Contrastive=1.2836, Archetype=0.1249\n",
      "Epoch 3, Batch 20/21: Loss=1.2953, Contrastive=1.8159, Archetype=0.0790\n",
      "\n",
      "Train Losses: {'total': np.float64(1.1765213580358596), 'contrastive': np.float64(1.641038940066383), 'archetype': np.float64(0.09356413621987615)}\n",
      "Val Losses: {'total': 1.8789116859436035, 'contrastive': 2.64446120262146, 'archetype': 0.0928520604968071}\n",
      "\n",
      "============================================================\n",
      "Epoch 5/20\n",
      "============================================================\n",
      "Epoch 4, Batch 0/21: Loss=1.0251, Contrastive=1.4264, Archetype=0.0850\n",
      "Epoch 4, Batch 10/21: Loss=0.8644, Contrastive=1.1844, Archetype=0.1128\n",
      "Epoch 4, Batch 20/21: Loss=0.8449, Contrastive=1.1762, Archetype=0.0720\n",
      "\n",
      "Train Losses: {'total': np.float64(0.8748027540388561), 'contrastive': np.float64(1.2104863240605308), 'archetype': np.float64(0.09098684752271288)}\n",
      "Val Losses: {'total': 1.9889604568481445, 'contrastive': 2.8006337165832518, 'archetype': 0.09593426436185837}\n",
      "\n",
      "============================================================\n",
      "Epoch 6/20\n",
      "============================================================\n",
      "Epoch 5, Batch 0/21: Loss=0.5452, Contrastive=0.7398, Archetype=0.0898\n",
      "Epoch 5, Batch 10/21: Loss=0.7601, Contrastive=1.0466, Archetype=0.0890\n",
      "Epoch 5, Batch 20/21: Loss=0.6293, Contrastive=0.8504, Archetype=0.1131\n",
      "\n",
      "Train Losses: {'total': np.float64(0.6353795798051924), 'contrastive': np.float64(0.8699700832366943), 'archetype': np.float64(0.0855060446830023)}\n",
      "Val Losses: {'total': 2.1827426195144652, 'contrastive': 3.0780548572540285, 'archetype': 0.09417669326066971}\n",
      "\n",
      "============================================================\n",
      "Epoch 7/20\n",
      "============================================================\n",
      "Epoch 6, Batch 0/21: Loss=0.5740, Contrastive=0.7763, Archetype=0.1003\n",
      "Epoch 6, Batch 10/21: Loss=0.3291, Contrastive=0.4354, Archetype=0.0757\n",
      "Epoch 6, Batch 20/21: Loss=0.3118, Contrastive=0.4105, Archetype=0.0729\n",
      "\n",
      "Train Losses: {'total': np.float64(0.47022737633614314), 'contrastive': np.float64(0.6349042767570132), 'archetype': np.float64(0.08273837608950478)}\n",
      "Val Losses: {'total': 2.063265252113342, 'contrastive': 2.907473611831665, 'archetype': 0.09361817836761474}\n",
      "\n",
      "============================================================\n",
      "Epoch 8/20\n",
      "============================================================\n",
      "Epoch 7, Batch 0/21: Loss=0.5361, Contrastive=0.7192, Archetype=0.1060\n",
      "Epoch 7, Batch 10/21: Loss=0.2735, Contrastive=0.3443, Archetype=0.1137\n",
      "Epoch 7, Batch 20/21: Loss=0.2198, Contrastive=0.2822, Archetype=0.0702\n",
      "\n",
      "Train Losses: {'total': np.float64(0.42333918667974924), 'contrastive': np.float64(0.5683076296533857), 'archetype': np.float64(0.0817239914266836)}\n",
      "Val Losses: {'total': 2.2311197996139525, 'contrastive': 3.1478755474090576, 'archetype': 0.09210832715034485}\n",
      "\n",
      "============================================================\n",
      "Epoch 9/20\n",
      "============================================================\n",
      "Epoch 8, Batch 0/21: Loss=0.2702, Contrastive=0.3546, Archetype=0.0665\n",
      "Epoch 8, Batch 10/21: Loss=0.2769, Contrastive=0.3609, Archetype=0.0728\n",
      "Epoch 8, Batch 20/21: Loss=0.3972, Contrastive=0.5295, Archetype=0.0823\n",
      "\n",
      "Train Losses: {'total': np.float64(0.3487282423746018), 'contrastive': np.float64(0.46316603464739664), 'archetype': np.float64(0.07680378073737734)}\n",
      "Val Losses: {'total': 2.0262681245803833, 'contrastive': 2.8576762199401857, 'archetype': 0.08364778906106948}\n",
      "\n",
      "============================================================\n",
      "Epoch 10/20\n",
      "============================================================\n",
      "Epoch 9, Batch 0/21: Loss=0.3399, Contrastive=0.4528, Archetype=0.0641\n",
      "Epoch 9, Batch 10/21: Loss=0.3858, Contrastive=0.5186, Archetype=0.0767\n",
      "Epoch 9, Batch 20/21: Loss=0.2204, Contrastive=0.2868, Archetype=0.0653\n",
      "\n",
      "Train Losses: {'total': np.float64(0.3181293337118058), 'contrastive': np.float64(0.420163251104809), 'archetype': np.float64(0.0748056024312973)}\n",
      "Val Losses: {'total': 2.2253603458404543, 'contrastive': 3.1394460201263428, 'archetype': 0.09274407923221588}\n",
      "Checkpoint saved to checkpoints/checkpoint_epoch_10.pth\n",
      "\n",
      "============================================================\n",
      "Epoch 11/20\n",
      "============================================================\n",
      "Epoch 10, Batch 0/21: Loss=0.2270, Contrastive=0.2931, Archetype=0.0656\n",
      "Epoch 10, Batch 10/21: Loss=0.2497, Contrastive=0.3341, Archetype=0.0518\n",
      "Epoch 10, Batch 20/21: Loss=0.1976, Contrastive=0.2572, Archetype=0.0513\n",
      "\n",
      "Train Losses: {'total': np.float64(0.21935686469078064), 'contrastive': np.float64(0.28001370813165394), 'archetype': np.float64(0.07175400072620028)}\n",
      "Val Losses: {'total': 2.0069974660873413, 'contrastive': 2.8290541648864744, 'archetype': 0.08775147646665574}\n",
      "\n",
      "============================================================\n",
      "Epoch 12/20\n",
      "============================================================\n",
      "Epoch 11, Batch 0/21: Loss=0.1624, Contrastive=0.2004, Archetype=0.0663\n",
      "Epoch 11, Batch 10/21: Loss=0.2642, Contrastive=0.3341, Archetype=0.0961\n",
      "Epoch 11, Batch 20/21: Loss=0.0869, Contrastive=0.0823, Archetype=0.0941\n",
      "\n",
      "Train Losses: {'total': np.float64(0.21585055689016977), 'contrastive': np.float64(0.27548178072486607), 'archetype': np.float64(0.07053832035689127)}\n",
      "Val Losses: {'total': 2.054126477241516, 'contrastive': 2.8973942756652833, 'archetype': 0.08465511798858642}\n",
      "\n",
      "============================================================\n",
      "Epoch 13/20\n",
      "============================================================\n",
      "Epoch 12, Batch 0/21: Loss=0.1397, Contrastive=0.1688, Archetype=0.0697\n",
      "Epoch 12, Batch 10/21: Loss=0.1212, Contrastive=0.1446, Archetype=0.0533\n",
      "Epoch 12, Batch 20/21: Loss=0.0776, Contrastive=0.0756, Archetype=0.0764\n",
      "\n",
      "Train Losses: {'total': np.float64(0.15598384929554804), 'contrastive': np.float64(0.19181581125372932), 'archetype': np.float64(0.06467146745749883)}\n",
      "Val Losses: {'total': 2.174279499053955, 'contrastive': 3.068585443496704, 'archetype': 0.08633935004472733}\n",
      "\n",
      "============================================================\n",
      "Epoch 14/20\n",
      "============================================================\n",
      "Epoch 13, Batch 0/21: Loss=0.2465, Contrastive=0.3146, Archetype=0.0717\n",
      "Epoch 13, Batch 10/21: Loss=0.1699, Contrastive=0.2140, Archetype=0.0591\n",
      "Epoch 13, Batch 20/21: Loss=0.2204, Contrastive=0.2809, Archetype=0.0726\n",
      "\n",
      "Train Losses: {'total': np.float64(0.1815546630393891), 'contrastive': np.float64(0.22804665565490723), 'archetype': np.float64(0.06609153428247996)}\n",
      "Val Losses: {'total': 2.013535213470459, 'contrastive': 2.838217830657959, 'archetype': 0.08829727321863175}\n",
      "\n",
      "============================================================\n",
      "Epoch 15/20\n",
      "============================================================\n",
      "Epoch 14, Batch 0/21: Loss=0.1276, Contrastive=0.1512, Archetype=0.0646\n",
      "Epoch 14, Batch 10/21: Loss=0.1117, Contrastive=0.1265, Archetype=0.0660\n",
      "Epoch 14, Batch 20/21: Loss=0.1084, Contrastive=0.1276, Archetype=0.0593\n",
      "\n",
      "Train Losses: {'total': np.float64(0.12121973257689249), 'contrastive': np.float64(0.14365368159044356), 'archetype': np.float64(0.06052998293723379)}\n",
      "Val Losses: {'total': 2.0229820013046265, 'contrastive': 2.852797746658325, 'archetype': 0.08558460175991059}\n",
      "\n",
      "============================================================\n",
      "Epoch 16/20\n",
      "============================================================\n",
      "Epoch 15, Batch 0/21: Loss=0.0560, Contrastive=0.0477, Archetype=0.0656\n",
      "Epoch 15, Batch 10/21: Loss=0.0432, Contrastive=0.0315, Archetype=0.0576\n",
      "Epoch 15, Batch 20/21: Loss=0.0858, Contrastive=0.0897, Archetype=0.0655\n",
      "\n",
      "Train Losses: {'total': np.float64(0.10762723570778257), 'contrastive': np.float64(0.12398805753106162), 'archetype': np.float64(0.062170179649477915)}\n",
      "Val Losses: {'total': 2.017869567871094, 'contrastive': 2.844854736328125, 'archetype': 0.08792515844106674}\n",
      "\n",
      "============================================================\n",
      "Epoch 17/20\n",
      "============================================================\n",
      "Epoch 16, Batch 0/21: Loss=0.1017, Contrastive=0.1099, Archetype=0.0731\n",
      "Epoch 16, Batch 10/21: Loss=0.1009, Contrastive=0.1148, Archetype=0.0540\n",
      "Epoch 16, Batch 20/21: Loss=0.0758, Contrastive=0.0730, Archetype=0.0736\n",
      "\n",
      "Train Losses: {'total': np.float64(0.10035211060728345), 'contrastive': np.float64(0.11597049378213428), 'archetype': np.float64(0.0545493449483599)}\n",
      "Val Losses: {'total': 2.4667022228240967, 'contrastive': 3.4876508712768555, 'archetype': 0.08237503618001937}\n",
      "\n",
      "============================================================\n",
      "Epoch 18/20\n",
      "============================================================\n",
      "Epoch 17, Batch 0/21: Loss=0.0905, Contrastive=0.0977, Archetype=0.0574\n",
      "Epoch 17, Batch 10/21: Loss=0.0498, Contrastive=0.0414, Archetype=0.0660\n",
      "Epoch 17, Batch 20/21: Loss=0.0732, Contrastive=0.0695, Archetype=0.0748\n",
      "\n",
      "Train Losses: {'total': np.float64(0.08132024925379526), 'contrastive': np.float64(0.08962785062335786), 'archetype': np.float64(0.052238624897741136)}\n",
      "Val Losses: {'total': 2.2642377376556397, 'contrastive': 3.1966292381286623, 'archetype': 0.08894703537225723}\n",
      "\n",
      "============================================================\n",
      "Epoch 19/20\n",
      "============================================================\n",
      "Epoch 18, Batch 0/21: Loss=0.1283, Contrastive=0.1575, Archetype=0.0468\n",
      "Epoch 18, Batch 10/21: Loss=0.1075, Contrastive=0.1134, Archetype=0.0864\n",
      "Epoch 18, Batch 20/21: Loss=0.1035, Contrastive=0.1276, Archetype=0.0410\n",
      "\n",
      "Train Losses: {'total': np.float64(0.08792954825219654), 'contrastive': np.float64(0.10021491898667245), 'archetype': np.float64(0.049678998156672434)}\n",
      "Val Losses: {'total': 2.2775218963623045, 'contrastive': 3.21718807220459, 'archetype': 0.084929059445858}\n",
      "\n",
      "============================================================\n",
      "Epoch 20/20\n",
      "============================================================\n",
      "Epoch 19, Batch 0/21: Loss=0.0525, Contrastive=0.0456, Archetype=0.0618\n",
      "Epoch 19, Batch 10/21: Loss=0.1323, Contrastive=0.1573, Archetype=0.0751\n",
      "Epoch 19, Batch 20/21: Loss=0.0329, Contrastive=0.0209, Archetype=0.0529\n",
      "\n",
      "Train Losses: {'total': np.float64(0.09401414862700871), 'contrastive': np.float64(0.10898664123600438), 'archetype': np.float64(0.05014375925418876)}\n",
      "Val Losses: {'total': 2.229612708091736, 'contrastive': 3.1474347591400145, 'archetype': 0.08981096595525742}\n",
      "Checkpoint saved to checkpoints/checkpoint_epoch_20.pth\n",
      "\n",
      "============================================================\n",
      "Training complete!\n",
      "============================================================\n",
      "Checkpoint saved to checkpoints/final_model.pth\n",
      "Training history plot saved to checkpoints/training_history.png\n",
      "\n",
      "✓ Training complete! Model checkpoints saved to checkpoints/\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Train!\n",
    "print(\"\\nStep 5: Starting training...\")\n",
    "pipeline.train()\n",
    "\n",
    "print(\"\\n✓ Training complete! Model checkpoints saved to checkpoints/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab3py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
