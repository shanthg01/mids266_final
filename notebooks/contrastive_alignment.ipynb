{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Contrastive Alignment Layer - CLAP-style Contrastive Learning\n",
    "Aligns text and audio embeddings in shared semantic space\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from typing import Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveAlignmentModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive learning module for aligning text and audio embeddings\n",
    "    \n",
    "    Implements:\n",
    "    - InfoNCE contrastive loss (CLAP-style)\n",
    "    - Auxiliary binary classifier for match prediction\n",
    "    - Temperature-scaled cosine similarity\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim=768,\n",
    "        temperature=0.07,\n",
    "        use_auxiliary_classifier=True,\n",
    "        device='cpu'\n",
    "    ):\n",
    "        super(ContrastiveAlignmentModule, self).__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.temperature = temperature\n",
    "        self.use_auxiliary_classifier = use_auxiliary_classifier\n",
    "        self.device = device\n",
    "        \n",
    "        # Learnable temperature parameter\n",
    "        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / temperature))\n",
    "        \n",
    "        # Auxiliary binary classifier for match prediction\n",
    "        if use_auxiliary_classifier:\n",
    "            self.match_classifier = nn.Sequential(\n",
    "                nn.Linear(embedding_dim * 2, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(512, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(256, 1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        self.to(device)\n",
    "    \n",
    "    def contrastive_loss(\n",
    "        self,\n",
    "        text_embeddings: torch.Tensor,\n",
    "        audio_embeddings: torch.Tensor,\n",
    "        labels: Optional[torch.Tensor] = None\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute InfoNCE contrastive loss\n",
    "        \n",
    "        Args:\n",
    "            text_embeddings: (batch_size, embedding_dim)\n",
    "            audio_embeddings: (batch_size, embedding_dim)\n",
    "            labels: Optional ground truth alignment (batch_size,)\n",
    "                   If None, assumes diagonal alignment (i-th text matches i-th audio)\n",
    "        \n",
    "        Returns:\n",
    "            Contrastive loss scalar\n",
    "        \"\"\"\n",
    "        batch_size = text_embeddings.shape[0]\n",
    "        \n",
    "        # Normalize embeddings\n",
    "        text_embeddings = F.normalize(text_embeddings, p=2, dim=1)\n",
    "        audio_embeddings = F.normalize(audio_embeddings, p=2, dim=1)\n",
    "        \n",
    "        # Compute cosine similarity matrix\n",
    "        logit_scale = self.logit_scale.exp()\n",
    "        logits = logit_scale * text_embeddings @ audio_embeddings.T\n",
    "        \n",
    "        # Create labels for positive pairs\n",
    "        if labels is None:\n",
    "            # Assume diagonal alignment\n",
    "            labels = torch.arange(batch_size, device=self.device)\n",
    "        \n",
    "        # Compute cross-entropy loss in both directions\n",
    "        loss_t2a = F.cross_entropy(logits, labels)  # Text to audio\n",
    "        loss_a2t = F.cross_entropy(logits.T, labels)  # Audio to text\n",
    "        \n",
    "        # Average bidirectional loss\n",
    "        loss = (loss_t2a + loss_a2t) / 2.0\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def auxiliary_match_loss(\n",
    "        self,\n",
    "        text_embeddings: torch.Tensor,\n",
    "        audio_embeddings: torch.Tensor,\n",
    "        match_labels: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute auxiliary binary classification loss for match prediction\n",
    "        \n",
    "        Args:\n",
    "            text_embeddings: (batch_size, embedding_dim)\n",
    "            audio_embeddings: (batch_size, embedding_dim)\n",
    "            match_labels: Binary labels (batch_size,) - 1 for match, 0 for no match\n",
    "        \n",
    "        Returns:\n",
    "            Binary cross-entropy loss\n",
    "        \"\"\"\n",
    "        if not self.use_auxiliary_classifier:\n",
    "            return torch.tensor(0.0, device=self.device)\n",
    "        \n",
    "        # Concatenate embeddings\n",
    "        combined = torch.cat([text_embeddings, audio_embeddings], dim=1)\n",
    "        \n",
    "        # Predict match probability\n",
    "        match_probs = self.match_classifier(combined).squeeze()\n",
    "        \n",
    "        # Binary cross-entropy loss\n",
    "        loss = F.binary_cross_entropy(match_probs, match_labels.float())\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def compute_similarity_matrix(\n",
    "        self,\n",
    "        text_embeddings: torch.Tensor,\n",
    "        audio_embeddings: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute pairwise similarity matrix between text and audio\n",
    "        \n",
    "        Returns:\n",
    "            Similarity matrix of shape (batch_text, batch_audio)\n",
    "        \"\"\"\n",
    "        # Normalize\n",
    "        text_embeddings = F.normalize(text_embeddings, p=2, dim=1)\n",
    "        audio_embeddings = F.normalize(audio_embeddings, p=2, dim=1)\n",
    "        \n",
    "        # Cosine similarity\n",
    "        similarity = text_embeddings @ audio_embeddings.T\n",
    "        \n",
    "        return similarity\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        text_embeddings: torch.Tensor,\n",
    "        audio_embeddings: torch.Tensor,\n",
    "        match_labels: Optional[torch.Tensor] = None,\n",
    "        compute_auxiliary: bool = True\n",
    "    ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Forward pass computing both losses\n",
    "        \n",
    "        Args:\n",
    "            text_embeddings: Text embeddings\n",
    "            audio_embeddings: Audio embeddings\n",
    "            match_labels: Optional binary match labels for auxiliary loss\n",
    "            compute_auxiliary: Whether to compute auxiliary loss\n",
    "        \n",
    "        Returns:\n",
    "            - Contrastive loss\n",
    "            - Auxiliary loss (if compute_auxiliary=True and match_labels provided)\n",
    "        \"\"\"\n",
    "        # Contrastive loss\n",
    "        contrastive_loss = self.contrastive_loss(text_embeddings, audio_embeddings)\n",
    "        \n",
    "        # Auxiliary loss\n",
    "        auxiliary_loss = None\n",
    "        if compute_auxiliary and match_labels is not None and self.use_auxiliary_classifier:\n",
    "            auxiliary_loss = self.auxiliary_match_loss(\n",
    "                text_embeddings, \n",
    "                audio_embeddings, \n",
    "                match_labels\n",
    "            )\n",
    "        \n",
    "        return contrastive_loss, auxiliary_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HardNegativeMiner:\n",
    "    \"\"\"\n",
    "    Mine hard negatives for contrastive learning\n",
    "    Selects challenging negative pairs to improve learning\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, margin=0.2):\n",
    "        self.margin = margin\n",
    "    \n",
    "    def mine_hard_negatives(\n",
    "        self,\n",
    "        text_embeddings: torch.Tensor,\n",
    "        audio_embeddings: torch.Tensor,\n",
    "        k: int = 3\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Find k hardest negative pairs for each anchor\n",
    "        \n",
    "        Args:\n",
    "            text_embeddings: (batch_size, embedding_dim)\n",
    "            audio_embeddings: (batch_size, embedding_dim)\n",
    "            k: Number of hard negatives per anchor\n",
    "        \n",
    "        Returns:\n",
    "            - Hard negative text indices\n",
    "            - Hard negative audio indices\n",
    "        \"\"\"\n",
    "        batch_size = text_embeddings.shape[0]\n",
    "        \n",
    "        # Compute similarity matrix\n",
    "        sim_matrix = text_embeddings @ audio_embeddings.T\n",
    "        \n",
    "        # Mask diagonal (positive pairs)\n",
    "        mask = torch.eye(batch_size, device=text_embeddings.device).bool()\n",
    "        sim_matrix_masked = sim_matrix.masked_fill(mask, -1e9)\n",
    "        \n",
    "        # Find top-k most similar negatives for each anchor\n",
    "        hard_neg_indices = torch.topk(sim_matrix_masked, k=k, dim=1).indices\n",
    "        \n",
    "        return hard_neg_indices, hard_neg_indices  # Symmetric for bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchCreator:\n",
    "    \"\"\"\n",
    "    Create training batches with positive and negative pairs\n",
    "    Ensures balanced sampling for contrastive learning\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, negative_ratio=2):\n",
    "        self.negative_ratio = negative_ratio\n",
    "    \n",
    "    def create_batch(\n",
    "        self,\n",
    "        text_embeddings: torch.Tensor,\n",
    "        audio_embeddings: torch.Tensor,\n",
    "        positive_pairs: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Create batch with positive and negative pairs\n",
    "        \n",
    "        Args:\n",
    "            text_embeddings: All text embeddings\n",
    "            audio_embeddings: All audio embeddings\n",
    "            positive_pairs: Indices of positive pairs (N, 2)\n",
    "        \n",
    "        Returns:\n",
    "            - Text batch\n",
    "            - Audio batch\n",
    "            - Labels (1 for positive, 0 for negative)\n",
    "        \"\"\"\n",
    "        num_positives = positive_pairs.shape[0]\n",
    "        num_negatives = num_positives * self.negative_ratio\n",
    "        \n",
    "        # Positive pairs\n",
    "        pos_text = text_embeddings[positive_pairs[:, 0]]\n",
    "        pos_audio = audio_embeddings[positive_pairs[:, 1]]\n",
    "        pos_labels = torch.ones(num_positives)\n",
    "        \n",
    "        # Sample random negative pairs\n",
    "        total_samples = text_embeddings.shape[0]\n",
    "        neg_text_idx = torch.randint(0, total_samples, (num_negatives,))\n",
    "        neg_audio_idx = torch.randint(0, total_samples, (num_negatives,))\n",
    "        \n",
    "        # Ensure negatives are actually negative (not in positive pairs)\n",
    "        neg_mask = neg_text_idx != neg_audio_idx\n",
    "        neg_text_idx = neg_text_idx[neg_mask][:num_negatives]\n",
    "        neg_audio_idx = neg_audio_idx[neg_mask][:num_negatives]\n",
    "        \n",
    "        neg_text = text_embeddings[neg_text_idx]\n",
    "        neg_audio = audio_embeddings[neg_audio_idx]\n",
    "        neg_labels = torch.zeros(len(neg_text_idx))\n",
    "        \n",
    "        # Combine\n",
    "        text_batch = torch.cat([pos_text, neg_text], dim=0)\n",
    "        audio_batch = torch.cat([pos_audio, neg_audio], dim=0)\n",
    "        labels = torch.cat([pos_labels, neg_labels], dim=0)\n",
    "        \n",
    "        # Shuffle\n",
    "        shuffle_idx = torch.randperm(text_batch.shape[0])\n",
    "        text_batch = text_batch[shuffle_idx]\n",
    "        audio_batch = audio_batch[shuffle_idx]\n",
    "        labels = labels[shuffle_idx]\n",
    "        \n",
    "        return text_batch, audio_batch, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Initialize contrastive module\n",
    "contrastive_module = ContrastiveAlignmentModule(\n",
    "    embedding_dim=768,\n",
    "    temperature=0.07,\n",
    "    use_auxiliary_classifier=True,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy embeddings\n",
    "batch_size = 16\n",
    "text_emb = torch.randn(batch_size, 768).to(device)\n",
    "audio_emb = torch.randn(batch_size, 768).to(device)\n",
    "\n",
    "# Normalize (as they would be from encoders)\n",
    "text_emb = F.normalize(text_emb, p=2, dim=1)\n",
    "audio_emb = F.normalize(audio_emb, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Contrastive Loss ===\n",
      "Contrastive loss: 2.8787\n"
     ]
    }
   ],
   "source": [
    "# Compute losses\n",
    "print(\"=== Testing Contrastive Loss ===\")\n",
    "contrastive_loss, _ = contrastive_module(text_emb, audio_emb, compute_auxiliary=False)\n",
    "print(f\"Contrastive loss: {contrastive_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Auxiliary Loss ===\n",
      "Contrastive loss: 2.8787\n",
      "Auxiliary loss: 0.6934\n"
     ]
    }
   ],
   "source": [
    "# Test with auxiliary loss\n",
    "print(\"\\n=== Testing Auxiliary Loss ===\")\n",
    "match_labels = torch.randint(0, 2, (batch_size,)).to(device)\n",
    "contrastive_loss, aux_loss = contrastive_module(\n",
    "    text_emb, \n",
    "    audio_emb, \n",
    "    match_labels=match_labels,\n",
    "    compute_auxiliary=True\n",
    ")\n",
    "print(f\"Contrastive loss: {contrastive_loss.item():.4f}\")\n",
    "print(f\"Auxiliary loss: {aux_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Similarity Matrix ===\n",
      "Similarity matrix shape: torch.Size([16, 16])\n",
      "Diagonal (positive pairs): -0.0029\n",
      "Off-diagonal (negative pairs): -0.0041\n"
     ]
    }
   ],
   "source": [
    "# Test similarity matrix\n",
    "print(\"\\n=== Testing Similarity Matrix ===\")\n",
    "sim_matrix = contrastive_module.compute_similarity_matrix(text_emb, audio_emb)\n",
    "print(f\"Similarity matrix shape: {sim_matrix.shape}\")\n",
    "print(f\"Diagonal (positive pairs): {torch.diag(sim_matrix).mean().item():.4f}\")\n",
    "print(f\"Off-diagonal (negative pairs): {(sim_matrix.sum() - torch.diag(sim_matrix).sum()) / (batch_size * (batch_size - 1)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Hard Negative Mining ===\n",
      "Hard negatives shape: torch.Size([16, 3])\n",
      "Sample hard negatives for anchor 0: tensor([ 2,  9, 10])\n"
     ]
    }
   ],
   "source": [
    "# Test hard negative mining\n",
    "print(\"\\n=== Testing Hard Negative Mining ===\")\n",
    "miner = HardNegativeMiner(margin=0.2)\n",
    "hard_negs, _ = miner.mine_hard_negatives(text_emb, audio_emb, k=3)\n",
    "print(f\"Hard negatives shape: {hard_negs.shape}\")\n",
    "print(f\"Sample hard negatives for anchor 0: {hard_negs[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab3py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
